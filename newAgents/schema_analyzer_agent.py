"""
Schema Analyzer Agent - RAGì™€ LLMì„ ê²°í•©í•œ ìŠ¤í‚¤ë§ˆ ì •ë³´ ê²€ìƒ‰ ë° ë¶„ì„
"""

from typing import Dict, Any, List, Optional
import json
import logging
import re

from rag.schema_retriever import schema_retriever
from langchain_openai import ChatOpenAI
from langchain.schema import HumanMessage, SystemMessage

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

class SchemaAnalyzerAgent:
    """RAGì™€ LLMì„ ì‚¬ìš©í•˜ì—¬ ê´€ë ¨ ìŠ¤í‚¤ë§ˆ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³  ë¶„ì„í•˜ëŠ” ì—ì´ì „íŠ¸"""
    
    def __init__(self, similarity_threshold: float = 0.3, max_tables: int = 7, model_name: str = "gpt-4-turbo"):
        """
        SchemaAnalyzer Agent ì´ˆê¸°í™”
        
        Args:
            similarity_threshold: ìœ ì‚¬ë„ ì„ê³„ê°’
            max_tables: ìµœëŒ€ ê²€ìƒ‰í•  í…Œì´ë¸” ìˆ˜
            model_name: ì‚¬ìš©í•  LLM ëª¨ë¸ëª…
        """
        print("ğŸ” SchemaAnalyzer Agent ì´ˆê¸°í™”")
        self.similarity_threshold = similarity_threshold
        self.max_tables = max_tables
        self.schema_retriever = schema_retriever
        self._initialized = False
        self.llm = ChatOpenAI(model=model_name, temperature=0.1)
    
    async def analyze_query(self, user_query: str) -> Dict[str, Any]:
        """
        ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ë¶„ì„í•˜ì—¬ ê´€ë ¨ ìŠ¤í‚¤ë§ˆ ì •ë³´ ê²€ìƒ‰
        
        Args:
            user_query: ì‚¬ìš©ì ìì—°ì–´ ì¿¼ë¦¬
            
        Returns:
            ìŠ¤í‚¤ë§ˆ ë¶„ì„ ê²°ê³¼
        """
        try:
            print(f"ğŸ” ìŠ¤í‚¤ë§ˆ ë¶„ì„ ì‹œì‘: {user_query}")
            
            if not self._initialized:
                if not await self._initialize_retriever():
                    return {"success": False, "error": "Schema Retriever ì´ˆê¸°í™” ì‹¤íŒ¨", "schema_info": []}
            
            relevant_tables = self._search_relevant_schemas(user_query)
            
            if not relevant_tables:
                print("âš ï¸ ê´€ë ¨ ìŠ¤í‚¤ë§ˆ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return {"success": True, "schema_info": [], "message": "ê´€ë ¨ ìŠ¤í‚¤ë§ˆ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
            
            analysis_result = await self._perform_relevance_analysis(user_query, relevant_tables)
            
            print(f"âœ… ìŠ¤í‚¤ë§ˆ ë¶„ì„ ì™„ë£Œ: {len(analysis_result.get('schema_info', []))}ê°œ í…Œì´ë¸”")
            
            return analysis_result
            
        except Exception as e:
            error_msg = f"ìŠ¤í‚¤ë§ˆ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}"
            print(f"âŒ {error_msg}")
            logger.error(error_msg, exc_info=True)
            return {"success": False, "error": error_msg, "schema_info": []}

    async def _perform_relevance_analysis(self, user_query: str, tables: List[Dict[str, Any]]) -> Dict[str, Any]:
        """LLMì„ ì´ìš©í•œ ê´€ë ¨ì„± ë° ì˜ë„ ì‹¬ì¸µ ë¶„ì„"""
        
        schema_info_str = self._format_schema_info_for_llm(tables)
        
        system_prompt = f"""
        ë‹¹ì‹ ì€ ìì—°ì–´ ì¿¼ë¦¬ì™€ ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆë¥¼ ë¶„ì„í•˜ëŠ” ì „ë¬¸ AI Agentì…ë‹ˆë‹¤.
        ì‚¬ìš©ìì˜ ìì—°ì–´ ì¿¼ë¦¬ì™€ RAGë¡œ ì¶”ì¶œëœ ìŠ¤í‚¤ë§ˆ ì •ë³´ë¥¼ ë¶„ì„í•˜ì—¬ SQL ìƒì„±ì— í•„ìš”í•œ êµ¬ì¡°í™”ëœ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë§Œë“œì„¸ìš”.

        **ë¶„ì„ í”„ë¡œì„¸ìŠ¤:**
        1. **ì¿¼ë¦¬ ì˜ë„ íŒŒì•… (Intent Analysis):** ì‚¬ìš©ìê°€ ë¬´ì—‡ì„ ì›í•˜ëŠ”ì§€ ëª…í™•íˆ ë¶„ì„í•©ë‹ˆë‹¤. (ì˜ˆ: COUNT, SUM, AVG, íŠ¹ì • ë°ì´í„° ì¡°íšŒ ë“±)
        2. **í•„í„° ì¡°ê±´ ì‹ë³„ (Filter Identification):** ì¿¼ë¦¬ì— í¬í•¨ëœ ì‹œê°„, ìƒíƒœ, íŠ¹ì • ê°’ ë“± ëª¨ë“  í•„í„°ë§ ì¡°ê±´ì„ ì‹ë³„í•©ë‹ˆë‹¤. (ì˜ˆ: ìµœê·¼ 7ì¼, íŠ¹ì • ì‚¬ìš©ì ë“±)
        3. **ìŠ¤í‚¤ë§ˆ ê´€ë ¨ì„± í‰ê°€ (Schema Relevance Assessment):** ì œê³µëœ ìŠ¤í‚¤ë§ˆ ì •ë³´ ì¤‘ ì‚¬ìš©ìì˜ ì˜ë„ì™€ ì§ì ‘ì ìœ¼ë¡œ ê´€ë ¨ëœ í…Œì´ë¸”ê³¼ **íŠ¹ì • ì»¬ëŸ¼ë“¤**ì„ ì‹ë³„í•©ë‹ˆë‹¤. ê´€ë ¨ ì—†ëŠ” ì •ë³´ëŠ” ê³¼ê°íˆ ì œì™¸í•©ë‹ˆë‹¤.
        4. **ìµœì¢… ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±**: ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ, SQL ìƒì„±ì— í•„ìš”í•œ ëª¨ë“  ì •ë³´ë¥¼ í¬í•¨í•œ ìµœì¢… JSONì„ ë°˜í™˜í•©ë‹ˆë‹¤.

        **ì‚¬ìš©ì ì¿¼ë¦¬:** {user_query}

        **RAGë¡œ ì¶”ì¶œëœ ìŠ¤í‚¤ë§ˆ ì •ë³´:**
        {schema_info_str}

        **ì‘ë‹µ í˜•ì‹ (JSON):**
        - ë°˜ë“œì‹œ ì•„ë˜ì˜ JSON í˜•ì‹ë§Œìœ¼ë¡œ ì‘ë‹µí•´ì•¼ í•©ë‹ˆë‹¤. ë‹¤ë¥¸ ì„¤ëª…ì€ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
        - `schema_info` í•„ë“œì—ëŠ” ìµœì¢…ì ìœ¼ë¡œ ê´€ë ¨ ìˆë‹¤ê³  íŒë‹¨ëœ í…Œì´ë¸”ì˜ ì •ë³´ë§Œ í¬í•¨í•©ë‹ˆë‹¤.
        - `relevant_columns`ì—ëŠ” í•´ë‹¹ í…Œì´ë¸”ì˜ ëª¨ë“  ì»¬ëŸ¼ì´ ì•„ë‹Œ, **ì¿¼ë¦¬ì™€ ì§ì ‘ ê´€ë ¨ëœ ì»¬ëŸ¼ë§Œ** í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.

        ```json
        {{
            "success": true,
            "query_analysis": {{
                "user_query": "{user_query}",
                "intent": "ì‚¬ìš©ì ì˜ë„(ì˜ˆ: COUNT, SUM, SELECT)",
                "filters": [
                    {{"type": "date_range", "period": "last_7_days", "column": "ì ìš©í•  ë‚ ì§œ ì»¬ëŸ¼ëª…"}},
                    {{"type": "value_filter", "column": "í•„í„°ë§í•  ì»¬ëŸ¼ëª…", "value": "í•„í„°ë§ ê°’"}}
                ],
                "natural_language_description": "LLMì´ ì´í•´í•œ ì‚¬ìš©ìì˜ ìš”ì²­ ë‚´ìš© ìš”ì•½"
            }},
            "schema_info": [
                {{
                    "table_name": "ê´€ë ¨ í…Œì´ë¸”ëª…",
                    "description": "í…Œì´ë¸” ì„¤ëª…",
                    "relevant_columns": [
                        {{"name": "ê´€ë ¨ ì»¬ëŸ¼ëª…1", "type": "ë°ì´í„°íƒ€ì…", "description": "ì»¬ëŸ¼ ì„¤ëª…"}},
                        {{"name": "ê´€ë ¨ ì»¬ëŸ¼ëª…2", "type": "ë°ì´í„°íƒ€ì…", "description": "ì»¬ëŸ¼ ì„¤ëª…"}}
                    ]
                }}
            ],
            "message": "Schema analysis completed successfully."
        }}
        ```
        """
        
        try:
            response = await self.llm.ainvoke([SystemMessage(content=system_prompt)])
            parsed_response = self._parse_json_response(response.content)
            
            if not parsed_response or not parsed_response.get("success"):
                return self._create_fallback_response(tables)
            
            return parsed_response

        except Exception as e:
            logger.error(f"LLM ê´€ë ¨ì„± ë¶„ì„ ì‹¤íŒ¨: {str(e)}", exc_info=True)
            return self._create_fallback_response(tables)

    def _format_schema_info_for_llm(self, tables: List[Dict[str, Any]]) -> str:
        """LLM ë¶„ì„ì„ ìœ„í•´ í…Œì´ë¸” ì •ë³´ë¥¼ ë¬¸ìì—´ë¡œ í¬ë§·"""
        # ... (ì´ì „ê³¼ ë™ì¼, ë³€ê²½ ì—†ìŒ) ...
        formatted_info = []
        for i, table in enumerate(tables, 1):
            table_name = table.get("table_name", f"table_{i}")
            description = table.get("description", "")
            columns = table.get("columns", [])
            
            schema_text = f"{i}. í…Œì´ë¸”: {table_name}\n   ì„¤ëª…: {description}\n   ì»¬ëŸ¼:\n"
            for col in columns:
                field_text = f"     - {col.get('name')} ({col.get('type')}): {col.get('description')}"
                schema_text += field_text + "\n"
            formatted_info.append(schema_text)
        
        return "\n".join(formatted_info)

    def _parse_json_response(self, response_content: str) -> Optional[Dict]:
        """LLMì˜ JSON ì‘ë‹µì„ íŒŒì‹±"""
        # ... (ì´ì „ê³¼ ë™ì¼, ë³€ê²½ ì—†ìŒ) ...
        try:
            match = re.search(r"```json\n(.*?)\n```", response_content, re.DOTALL)
            if match:
                content = match.group(1)
            else:
                content = response_content
            
            return json.loads(content.strip())
        except json.JSONDecodeError as e:
            logger.warning(f"JSON íŒŒì‹± ì‹¤íŒ¨: {str(e)}\nì›ë³¸ ë‚´ìš©: {response_content[:200]}...")
            return None

    def _create_fallback_response(self, tables: List[Dict[str, Any]]) -> Dict[str, Any]:
        """LLM ë¶„ì„ ì‹¤íŒ¨ ì‹œ, RAG ê²°ê³¼ ê¸°ë°˜ì˜ ê¸°ë³¸ ì‘ë‹µ ìƒì„±"""
        # ... (ì´ì „ê³¼ ë™ì¼, ë³€ê²½ ì—†ìŒ) ...
        print("âš ï¸ LLM ë¶„ì„ ì‹¤íŒ¨. RAG ê²€ìƒ‰ ê²°ê³¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
        return {
            "success": True,
            "schema_info": self._process_schema_info(tables),
            "message": "LLM ë¶„ì„ì— ì‹¤íŒ¨í•˜ì—¬, ê²€ìƒ‰ëœ ìŠ¤í‚¤ë§ˆ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤."
        }

    async def _initialize_retriever(self) -> bool:
        """Schema Retriever ì´ˆê¸°í™”"""
        # ... (ì´ì „ê³¼ ë™ì¼, ë³€ê²½ ì—†ìŒ) ...
        try:
            print("ğŸš€ Schema Retriever ì´ˆê¸°í™” ì¤‘...")
            if self.schema_retriever.initialize():
                self._initialized = True
                print("âœ… Schema Retriever ì´ˆê¸°í™” ì™„ë£Œ")
                return True
            return False
        except Exception as e:
            print(f"âŒ Schema Retriever ì´ˆê¸°í™” ì˜¤ë¥˜: {str(e)}")
            return False
    
    def _search_relevant_schemas(self, user_query: str) -> List[Dict]:
        """ê´€ë ¨ ìŠ¤í‚¤ë§ˆ ì •ë³´ ê²€ìƒ‰"""
        # ... (ì´ì „ê³¼ ë™ì¼, ë³€ê²½ ì—†ìŒ) ...
        try:
            return self.schema_retriever.get_relevant_tables_with_threshold(
                query=user_query,
                top_k=self.max_tables,
                similarity_threshold=self.similarity_threshold
            )
        except Exception as e:
            print(f"âŒ ìŠ¤í‚¤ë§ˆ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return []
    
    def _process_schema_info(self, schema_info: List[Dict]) -> List[Dict]:
        """ìŠ¤í‚¤ë§ˆ ì •ë³´ í›„ì²˜ë¦¬ ë° ì •ì œ"""
        # ... (ì´ì „ê³¼ ë™ì¼, ë³€ê²½ ì—†ìŒ) ...
        processed_schemas = []
        for table_info in schema_info:
            processed_table = {
                "table_name": table_info.get("table_name", ""),
                "description": table_info.get("description", ""),
                "columns": table_info.get("columns", [])
            }
            processed_schemas.append(processed_table)
        return processed_schemas

# ì „ì—­ SchemaAnalyzer ì¸ìŠ¤í„´ìŠ¤
schema_analyzer_agent = SchemaAnalyzerAgent()