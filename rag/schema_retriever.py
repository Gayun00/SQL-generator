"""
Schema Retriever - ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê´€ë ¨ ìŠ¤í‚¤ë§ˆ ê²€ìƒ‰
"""

from typing import List, Dict, Optional, Tuple
from langchain_chroma import Chroma
from langchain_openai import OpenAIEmbeddings
from langchain.schema import Document
from rag.schema_embedder import schema_embedder

class SchemaRetriever:
    def __init__(self, top_k: int = 5):
        """
        ìŠ¤í‚¤ë§ˆ ê²€ìƒ‰ê¸° ì´ˆê¸°í™”
        
        Args:
            top_k: ê²€ìƒ‰í•  ìƒìœ„ ë¬¸ì„œ ìˆ˜
        """
        self.top_k = top_k
        self.embeddings = OpenAIEmbeddings()
        self.vectorstore = None
        
    def initialize(self) -> bool:
        """ê²€ìƒ‰ê¸° ì´ˆê¸°í™”"""
        try:
            # schema_embedderì˜ ë²¡í„°ìŠ¤í† ì–´ ì‚¬ìš©
            if not schema_embedder.vectorstore:
                if not schema_embedder.initialize_vectorstore():
                    return False
            
            self.vectorstore = schema_embedder.vectorstore
            print("âœ… ìŠ¤í‚¤ë§ˆ ê²€ìƒ‰ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
            return True
            
        except Exception as e:
            print(f"âŒ ìŠ¤í‚¤ë§ˆ ê²€ìƒ‰ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
            return False
    
    def search_relevant_schemas(self, query: str, top_k: Optional[int] = None) -> List[Document]:
        """
        ì¿¼ë¦¬ì™€ ê´€ë ¨ëœ ìŠ¤í‚¤ë§ˆ ê²€ìƒ‰
        
        Args:
            query: ì‚¬ìš©ì ìì—°ì–´ ì¿¼ë¦¬
            top_k: ê²€ìƒ‰í•  ë¬¸ì„œ ìˆ˜
            
        Returns:
            ê´€ë ¨ Document ë¦¬ìŠ¤íŠ¸
        """
        if not self.vectorstore:
            print("âŒ ë²¡í„°ìŠ¤í† ì–´ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return []
        
        search_k = top_k or self.top_k
        
        try:
            print(f"ğŸ” ì¿¼ë¦¬ ê²€ìƒ‰ ì¤‘: '{query}'")
            
            # ìœ ì‚¬ë„ ê²€ìƒ‰ ìˆ˜í–‰
            results = self.vectorstore.similarity_search_with_score(
                query=query,
                k=search_k
            )
            
            print(f"ğŸ“Š ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ ë¬¸ì„œ ë°œê²¬")
            
            # ê²°ê³¼ ì •ë¦¬
            documents = []
            for doc, score in results:
                print(f"   - {doc.metadata.get('type', 'unknown')}: {doc.metadata.get('table_name', 'unknown')} (score: {score:.3f})")
                documents.append(doc)
            
            return documents
            
        except Exception as e:
            print(f"âŒ ìŠ¤í‚¤ë§ˆ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
            return []

    def search_relevant_schemas_with_threshold(self, query: str, top_k: Optional[int] = None, similarity_threshold: float = 0.5) -> List[Document]:
        """
        ìœ ì‚¬ë„ ì„ê³„ê°’ì„ ì ìš©í•œ ìŠ¤í‚¤ë§ˆ ê²€ìƒ‰
        
        Args:
            query: ì‚¬ìš©ì ìì—°ì–´ ì¿¼ë¦¬
            top_k: ê²€ìƒ‰í•  ë¬¸ì„œ ìˆ˜
            similarity_threshold: ìœ ì‚¬ë„ ì„ê³„ê°’ (0.0 ~ 1.0, ë†’ì„ìˆ˜ë¡ ì—„ê²©)
            
        Returns:
            ì„ê³„ê°’ ì´ìƒì˜ ìœ ì‚¬ë„ë¥¼ ê°€ì§„ Document ë¦¬ìŠ¤íŠ¸
        """
        if not self.vectorstore:
            print("âŒ ë²¡í„°ìŠ¤í† ì–´ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return []
        
        search_k = top_k or self.top_k
        
        try:
            print(f"ğŸ” ì¿¼ë¦¬ ê²€ìƒ‰ ì¤‘ (ì„ê³„ê°’: {similarity_threshold}): '{query}'")
            
            # ìœ ì‚¬ë„ ê²€ìƒ‰ ìˆ˜í–‰
            results = self.vectorstore.similarity_search_with_score(
                query=query,
                k=search_k
            )
            
            # ìœ ì‚¬ë„ ì„ê³„ê°’ ì ìš© í•„í„°ë§
            filtered_documents = []
            for doc, score in results:
                # ChromaDBëŠ” distanceë¥¼ ë°˜í™˜í•˜ë¯€ë¡œ similarity = 1 - distanceë¡œ ê³„ì‚°
                # ë‹¨, distanceê°€ ì´ë¯¸ similarityì¼ ìˆ˜ë„ ìˆìœ¼ë‹ˆ ë²”ìœ„ í™•ì¸
                if score <= 1.0:  # scoreê°€ distanceì¸ ê²½ìš°
                    similarity = 1.0 - score
                else:  # scoreê°€ ì´ë¯¸ similarityì¸ ê²½ìš°
                    similarity = score
                
                print(f"   - {doc.metadata.get('type', 'unknown')}: {doc.metadata.get('table_name', 'unknown')} (similarity: {similarity:.3f})")
                
                if similarity >= similarity_threshold:
                    filtered_documents.append(doc)
                else:
                    print(f"     â†’ ì„ê³„ê°’ ë¯¸ë‹¬ë¡œ ì œì™¸ (required: {similarity_threshold})")
            
            print(f"ğŸ“Š í•„í„°ë§ ê²°ê³¼: {len(results)}ê°œ ì¤‘ {len(filtered_documents)}ê°œ ì„ íƒ")
            
            return filtered_documents
            
        except Exception as e:
            print(f"âŒ ìŠ¤í‚¤ë§ˆ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
            return []
    
    def get_relevant_tables(self, query: str, top_k: Optional[int] = None) -> List[Dict]:
        """
        ì¿¼ë¦¬ì™€ ê´€ë ¨ëœ í…Œì´ë¸” ì •ë³´ë§Œ ì¶”ì¶œ
        
        Args:
            query: ì‚¬ìš©ì ìì—°ì–´ ì¿¼ë¦¬
            top_k: ê²€ìƒ‰í•  ë¬¸ì„œ ìˆ˜
            
        Returns:
            í…Œì´ë¸” ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        documents = self.search_relevant_schemas(query, top_k)
        
        # í…Œì´ë¸”ë³„ë¡œ ê·¸ë£¹í™”
        tables = {}
        
        for doc in documents:
            table_name = doc.metadata.get('table_name')
            if not table_name:
                continue
            
            if table_name not in tables:
                tables[table_name] = {
                    'table_name': table_name,
                    'dataset': doc.metadata.get('dataset', ''),
                    'table_id': doc.metadata.get('table_id', ''),
                    'description': doc.metadata.get('description', ''),
                    'columns': [],
                    'relevance_score': 0,
                    'matched_elements': []
                }
            
            # ë¬¸ì„œ íƒ€ì…ì— ë”°ë¼ ì²˜ë¦¬
            doc_type = doc.metadata.get('type')
            if doc_type == 'table':
                tables[table_name]['description'] = doc.metadata.get('description', '')
                tables[table_name]['matched_elements'].append('table_description')
            elif doc_type == 'column':
                column_info = {
                    'name': doc.metadata.get('column_name', ''),
                    'type': doc.metadata.get('column_type', ''),
                    'mode': doc.metadata.get('column_mode', ''),
                    'description': doc.metadata.get('column_description', '')
                }
                if column_info not in tables[table_name]['columns']:
                    tables[table_name]['columns'].append(column_info)
                    tables[table_name]['matched_elements'].append(f"column_{column_info['name']}")
        
        # ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ ë° ê´€ë ¨ì„± ìˆœìœ¼ë¡œ ì •ë ¬
        table_list = list(tables.values())
        table_list.sort(key=lambda x: len(x['matched_elements']), reverse=True)
        
        return table_list

    def get_relevant_tables_with_threshold(self, query: str, top_k: Optional[int] = None, similarity_threshold: float = 0.5) -> List[Dict]:
        """
        ìœ ì‚¬ë„ ì„ê³„ê°’ì„ ì ìš©í•œ ê´€ë ¨ í…Œì´ë¸” ì •ë³´ ì¶”ì¶œ
        
        Args:
            query: ì‚¬ìš©ì ìì—°ì–´ ì¿¼ë¦¬
            top_k: ê²€ìƒ‰í•  ë¬¸ì„œ ìˆ˜
            similarity_threshold: ìœ ì‚¬ë„ ì„ê³„ê°’ (0.0 ~ 1.0, ë†’ì„ìˆ˜ë¡ ì—„ê²©)
            
        Returns:
            ì„ê³„ê°’ ì´ìƒì˜ ìœ ì‚¬ë„ë¥¼ ê°€ì§„ í…Œì´ë¸” ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        documents = self.search_relevant_schemas_with_threshold(query, top_k, similarity_threshold)
        
        if not documents:
            return []
        
        # í…Œì´ë¸”ë³„ë¡œ ê·¸ë£¹í™”
        tables = {}
        
        for doc in documents:
            table_name = doc.metadata.get('table_name')
            if not table_name:
                continue
            
            if table_name not in tables:
                tables[table_name] = {
                    'table_name': table_name,
                    'dataset': doc.metadata.get('dataset', ''),
                    'table_id': doc.metadata.get('table_id', ''),
                    'description': doc.metadata.get('description', ''),
                    'columns': [],
                    'relevance_score': 0,
                    'matched_elements': []
                }
            
            # ë¬¸ì„œ íƒ€ì…ì— ë”°ë¼ ì²˜ë¦¬
            doc_type = doc.metadata.get('type')
            if doc_type == 'table':
                tables[table_name]['description'] = doc.metadata.get('description', '')
                tables[table_name]['matched_elements'].append('table_description')
            elif doc_type == 'column':
                column_info = {
                    'name': doc.metadata.get('column_name', ''),
                    'type': doc.metadata.get('column_type', ''),
                    'mode': doc.metadata.get('column_mode', ''),
                    'description': doc.metadata.get('column_description', '')
                }
                if column_info not in tables[table_name]['columns']:
                    tables[table_name]['columns'].append(column_info)
                    tables[table_name]['matched_elements'].append(f"column_{column_info['name']}")
        
        # ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ ë° ê´€ë ¨ì„± ìˆœìœ¼ë¡œ ì •ë ¬
        table_list = list(tables.values())
        table_list.sort(key=lambda x: len(x['matched_elements']), reverse=True)
        
        return table_list
    
    def create_context_summary(self, query: str, max_tables: int = 3) -> str:
        """
        ì¿¼ë¦¬ì— ëŒ€í•œ ì»¨í…ìŠ¤íŠ¸ ìš”ì•½ ìƒì„±
        
        Args:
            query: ì‚¬ìš©ì ìì—°ì–´ ì¿¼ë¦¬
            max_tables: í¬í•¨í•  ìµœëŒ€ í…Œì´ë¸” ìˆ˜
            
        Returns:
            ì»¨í…ìŠ¤íŠ¸ ìš”ì•½ ë¬¸ìì—´
        """
        relevant_tables = self.get_relevant_tables(query, top_k=10)
        
        if not relevant_tables:
            return "ê´€ë ¨ ìŠ¤í‚¤ë§ˆ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # ìƒìœ„ í…Œì´ë¸”ë“¤ë§Œ ì„ íƒ
        selected_tables = relevant_tables[:max_tables]
        
        context_parts = []
        context_parts.append("=== ì¿¼ë¦¬ì™€ ê´€ë ¨ëœ í…Œì´ë¸” ì •ë³´ ===\n")
        
        for i, table in enumerate(selected_tables, 1):
            context_parts.append(f"{i}. í…Œì´ë¸”: {table['table_name']}")
            
            if table['description']:
                context_parts.append(f"   ì„¤ëª…: {table['description']}")
            
            if table['columns']:
                context_parts.append("   ì£¼ìš” ì»¬ëŸ¼:")
                for col in table['columns'][:5]:  # ìƒìœ„ 5ê°œ ì»¬ëŸ¼ë§Œ
                    col_desc = f" - {col['description']}" if col['description'] else ""
                    context_parts.append(f"     â€¢ {col['name']} ({col['type']}, {col['mode']}){col_desc}")
                
                if len(table['columns']) > 5:
                    context_parts.append(f"     ... ë° {len(table['columns']) - 5}ê°œ ì»¬ëŸ¼ ë”")
            
            context_parts.append("")  # ë¹ˆ ì¤„
        
        return "\n".join(context_parts)
    
    def get_statistics(self) -> Dict:
        """ê²€ìƒ‰ê¸° í†µê³„ ì •ë³´"""
        if not self.vectorstore:
            return {"status": "not_initialized"}
        
        try:
            collection_info = schema_embedder.get_collection_info()
            return {
                "status": "ready",
                "collection_name": collection_info.get("collection_name", "unknown"),
                "document_count": collection_info.get("document_count", 0),
                "persist_directory": collection_info.get("persist_directory", "unknown")
            }
        except Exception as e:
            return {"status": "error", "error": str(e)}

# ì „ì—­ ê²€ìƒ‰ê¸° ì¸ìŠ¤í„´ìŠ¤
schema_retriever = SchemaRetriever()