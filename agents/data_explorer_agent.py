"""
DataExplorer Agent - Îç∞Ïù¥ÌÑ∞ ÌÉêÏÉâ Î∞è Î∂àÌôïÏã§ÏÑ± Ìï¥Í≤∞ Ï†ÑÎ¨∏ Agent

Í∏∞Ï°¥ sql_explorer ÎÖ∏ÎìúÎ•º AgentÎ°ú Î≥ÄÌôòÌïòÏó¨ Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ ÌÉêÏÉâ,
Î∂àÌôïÏã§ÏÑ± Ìï¥Í≤∞, Ïù∏ÏÇ¨Ïù¥Ìä∏ Î∞úÍ≤¨Ïóê ÌäπÌôîÎêú ÏßÄÎä•Ìòï AgentÎ°ú Íµ¨ÌòÑÌñàÏäµÎãàÎã§.
"""

from typing import Dict, Any, List, Optional
import logging
from datetime import datetime
import json
import re

from .base_agent import BaseAgent, AgentMessage, MessageType, AgentConfig, create_agent_config
from db.bigquery_client import bq_client
from langchain.schema import HumanMessage, SystemMessage

logger = logging.getLogger(__name__)

class ExplorationStrategy:
    """ÌÉêÏÉâ Ï†ÑÎûµ Î∂ÑÎ•ò"""
    QUICK_SCAN = "quick_scan"           # Îπ†Î•∏ Ïä§Ï∫î (LIMIT 10)
    STATISTICAL = "statistical"        # ÌÜµÍ≥ÑÏ†Å Î∂ÑÏÑù 
    RELATIONSHIP = "relationship"       # ÌÖåÏù¥Î∏î Í∞Ñ Í¥ÄÍ≥Ñ ÌÉêÏÉâ
    VALUE_DISCOVERY = "value_discovery" # Ïª¨Îüº Í∞í ÌÉêÏÉâ
    TEMPORAL_ANALYSIS = "temporal"      # ÏãúÍ∞Ñ Í∏∞Î∞ò Î∂ÑÏÑù

class DataExplorerAgent(BaseAgent):
    """Îç∞Ïù¥ÌÑ∞ ÌÉêÏÉâ Î∞è Î∂àÌôïÏã§ÏÑ± Ìï¥Í≤∞ Ï†ÑÎ¨∏ Agent"""
    
    def __init__(self, config: Optional[AgentConfig] = None):
        if config is None:
            config = create_agent_config(
                name="data_explorer",
                specialization="data_exploration_investigation",
                model="gpt-4",
                temperature=0.2,  # ÌÉêÏÉâÏùò Îã§ÏñëÏÑ±Í≥º ÏïàÏ†ïÏÑ± Í∑†Ìòï
                max_tokens=1200
            )
        
        super().__init__(config)
        
        # ÌÉêÏÉâ Ï†ÑÏö© ÏÑ§Ï†ï
        self.exploration_strategies = {
            ExplorationStrategy.QUICK_SCAN: "Îπ†Î•∏ Îç∞Ïù¥ÌÑ∞ Ïä§Ï∫î Î∞è Íµ¨Ï°∞ ÌååÏïÖ",
            ExplorationStrategy.STATISTICAL: "ÌÜµÍ≥ÑÏ†Å Î∂ÑÏÑù Î∞è ÏßëÍ≥Ñ",
            ExplorationStrategy.RELATIONSHIP: "ÌÖåÏù¥Î∏î Í∞Ñ Í¥ÄÍ≥Ñ Î∂ÑÏÑù",
            ExplorationStrategy.VALUE_DISCOVERY: "Ïª¨Îüº Í∞í Î∞è Ìå®ÌÑ¥ ÌÉêÏÉâ",
            ExplorationStrategy.TEMPORAL_ANALYSIS: "ÏãúÍ∞Ñ Í∏∞Î∞ò Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù"
        }
        
        # ÏÑ±Îä• Ï∂îÏ†Å
        self.exploration_history = []
        self.investigation_stats = {
            "total_explorations": 0,
            "successful_explorations": 0,
            "insights_discovered": 0,
            "avg_exploration_time": 0.0,
            "uncertainty_resolution_rate": 0.0
        }
        
    
    def get_system_prompt(self) -> str:
        """DataExplorer ÏãúÏä§ÌÖú ÌîÑÎ°¨ÌîÑÌä∏"""
        return f"""
        ÎãπÏã†ÏùÄ BigQuery Îç∞Ïù¥ÌÑ∞ ÌÉêÏÉâ Ï†ÑÎ¨∏Í∞ÄÏûÖÎãàÎã§.
        
        üö® **ÌïµÏã¨ Í∑úÏπô: BigQuery Standard SQLÎßå ÏÇ¨Ïö©ÌïòÏÑ∏Ïöî!**
        
        **BigQuery Î¨∏Î≤ï Í∑úÏπô:**
        - ÌÖåÏù¥Î∏îÎ™Ö: `project.dataset.table` (Î∞±Ìã± ÌïÑÏàò)
        - LIMIT: LIMIT 20 (MySQLÏùò LIMIT offset, count Í∏àÏßÄ)
        - Ïä§ÌÇ§Îßà Ï°∞Ìöå: INFORMATION_SCHEMA ÏÇ¨Ïö©
        - Ï†àÎåÄ Í∏àÏßÄ: DESCRIBE, SHOW TABLES, SHOW COLUMNS Îì± MySQL Î¨∏Î≤ï
        
        **ÌÉêÏÉâ Ï†ÑÎûµ:**
        - Îπ†Î•∏ Ïä§Ï∫î: LIMIT 10-20 ÏÇ¨Ïö©
        - ÏïàÏ†ÑÌïú ÏøºÎ¶¨: ÏóêÎü¨ Î∞©ÏßÄÎ•º ÏúÑÌïú SAFE_CAST Îì± ÏÇ¨Ïö©
        - Ìö®Ïú®Ï†ÅÏù∏ ÌÉêÏÉâ: Î∂àÌïÑÏöîÌïú Îç∞Ïù¥ÌÑ∞ Î°úÎìú Î∞©ÏßÄ
        
        **ÌíàÏßà Î™©Ìëú:**
        - BigQuery Î¨∏Î≤ï Ï§ÄÏàòÏú®: 100%
        - ÌÉêÏÉâ ÏãúÍ∞Ñ: 2-5Ï¥à
        - Î∂àÌôïÏã§ÏÑ± Ìï¥Í≤∞Î•†: 80% Ïù¥ÏÉÅ
        """
    
    async def process_message(self, message: AgentMessage) -> AgentMessage:
        """Î©îÏãúÏßÄ Ï≤òÎ¶¨ - Îç∞Ïù¥ÌÑ∞ ÌÉêÏÉâ ÏûëÏóÖ ÏàòÌñâ"""
        try:
            # ÏûÖÎ†• Ïú†Ìö®ÏÑ± Í≤ÄÏ¶ù
            if not await self.validate_input(message):
                return self.create_error_message(message, ValueError("Invalid input message"))
            
            # Î©îÏãúÏßÄ ÌûàÏä§ÌÜ†Î¶¨Ïóê Ï∂îÍ∞Ä
            self.add_message_to_history(message)
            
            # ÏûëÏóÖ ÌÉÄÏûÖÏóê Îî∞Î•∏ Ï≤òÎ¶¨
            task_type = message.content.get("task_type", "uncertainty_exploration")
            input_data = message.content.get("input_data", {})
            
            if task_type == "uncertainty_exploration":
                result = await self._uncertainty_exploration(input_data)
            elif task_type == "data_discovery":
                result = await self._data_discovery(input_data)
            elif task_type == "relationship_analysis":
                result = await self._relationship_analysis(input_data)
            elif task_type == "statistical_analysis":
                result = await self._statistical_analysis(input_data)
            else:
                result = await self._uncertainty_exploration(input_data)  # Í∏∞Î≥∏Í∞í
            
            # ÏÑ±Í≥µ ÏùëÎãµ ÏÉùÏÑ±
            return self.create_response_message(message, result)
            
        except Exception as e:
            logger.error(f"DataExplorer Agent processing failed: {str(e)}")
            return self.create_error_message(message, e)
    
    async def _uncertainty_exploration(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """Î∂àÌôïÏã§ÏÑ± Ìï¥Í≤∞ÏùÑ ÏúÑÌïú ÌÉêÏÉâ - ÌëúÏ§Ä Ï≤òÎ¶¨"""
        uncertainties = input_data.get("uncertainties", [])
        query = input_data.get("query", "")
        
        logger.info(f"DataExplorer: Uncertainty exploration for {len(uncertainties)} items")
        
        if not uncertainties:
            return {
                "exploration_type": "uncertainty_exploration",
                "executed_queries": 0,
                "results": [],
                "insights": [],
                "summary": "ÌÉêÏÉâÌï† Î∂àÌôïÏã§ÏÑ±Ïù¥ ÏóÜÏäµÎãàÎã§.",
                "resolution_success": True
            }
        
        exploration_results = {
            "exploration_type": "uncertainty_exploration",
            "executed_queries": 0,
            "results": [],
            "insights": [],
            "summary": "",
            "resolution_success": False
        }
        
        start_time = datetime.now()
        successful_explorations = 0
        
        for i, uncertainty in enumerate(uncertainties, 1):
            logger.info(f"Processing uncertainty {i}/{len(uncertainties)}: {uncertainty.get('type', 'unknown')}")
            
            exploration_result = await self._explore_single_uncertainty(uncertainty, query)
            exploration_results["results"].append(exploration_result)
            
            if exploration_result["success"]:
                successful_explorations += 1
                exploration_results["executed_queries"] += 1
                
                # Ïù∏ÏÇ¨Ïù¥Ìä∏ Ï∂îÍ∞Ä
                if exploration_result.get("insight"):
                    exploration_results["insights"].append(exploration_result["insight"])
        
        # Ï†ÑÏ≤¥ Í≤∞Í≥º ÏöîÏïΩ
        processing_time = (datetime.now() - start_time).total_seconds()
        exploration_results["summary"] = f"{successful_explorations}/{len(uncertainties)}Í∞ú Î∂àÌôïÏã§ÏÑ± Ìï¥Í≤∞ ÏôÑÎ£å"
        exploration_results["resolution_success"] = successful_explorations > 0
        exploration_results["processing_time"] = processing_time
        
        # ÌÜµÍ≥Ñ ÏóÖÎç∞Ïù¥Ìä∏
        self._update_exploration_stats(len(uncertainties), successful_explorations, processing_time)
        
        logger.info(f"Uncertainty exploration completed: {exploration_results['summary']}")
        return exploration_results
    
    async def _explore_single_uncertainty(self, uncertainty: Dict, original_query: str) -> Dict[str, Any]:
        """Îã®Ïùº Î∂àÌôïÏã§ÏÑ± ÌÉêÏÉâ"""
        uncertainty_type = uncertainty.get("type", "unknown")
        description = uncertainty.get("description", "")
        
        try:
            # ÌÉêÏÉâ ÏøºÎ¶¨ ÏûêÎèô ÏÉùÏÑ±
            exploration_query = await self._generate_exploration_query(uncertainty, original_query)
            
            if not exploration_query:
                return {
                    "uncertainty_type": uncertainty_type,
                    "description": description,
                    "success": False,
                    "error": "ÌÉêÏÉâ ÏøºÎ¶¨ ÏÉùÏÑ± Ïã§Ìå®",
                    "insight": f"{uncertainty_type} Î∂àÌôïÏã§ÏÑ±ÏùÑ Ìï¥Í≤∞Ìï† ÌÉêÏÉâ ÏøºÎ¶¨Î•º ÏÉùÏÑ±Ìï† Ïàò ÏóÜÏäµÎãàÎã§."
                }
            
            # ÌÉêÏÉâ ÏøºÎ¶¨ Ïã§Ìñâ
            logger.info(f"Executing exploration query: {exploration_query[:100]}...")
            query_result = bq_client.execute_query(exploration_query, max_results=20)
            
            if query_result["success"]:
                # Í≤∞Í≥º Î∂ÑÏÑù Î∞è Ïù∏ÏÇ¨Ïù¥Ìä∏ ÏÉùÏÑ±
                insight = await self._analyze_exploration_result(uncertainty, query_result)
                
                return {
                    "uncertainty_type": uncertainty_type,
                    "description": description,
                    "exploration_query": exploration_query,
                    "success": True,
                    "data": query_result["results"][:10],  # ÏÉÅÏúÑ 10Í∞úÎßå Ï†ÄÏû•
                    "total_rows": query_result["total_rows"],
                    "returned_rows": query_result["returned_rows"],
                    "insight": insight,
                    "resolution_confidence": self._calculate_resolution_confidence(query_result)
                }
            else:
                return {
                    "uncertainty_type": uncertainty_type,
                    "description": description,
                    "exploration_query": exploration_query,
                    "success": False,
                    "error": query_result["error"],
                    "insight": f"ÌÉêÏÉâ Ïã§Ìå®Î°ú {uncertainty_type} Î∂àÌôïÏã§ÏÑ±ÏùÑ Ìï¥Í≤∞Ìï† Ïàò ÏóÜÏäµÎãàÎã§."
                }
                
        except Exception as e:
            logger.error(f"Single uncertainty exploration failed: {str(e)}")
            return {
                "uncertainty_type": uncertainty_type,
                "description": description,
                "success": False,
                "error": str(e),
                "insight": f"Ïò§Î•òÎ°ú Ïù∏Ìï¥ {uncertainty_type} Î∂àÌôïÏã§ÏÑ±ÏùÑ Ìï¥Í≤∞Ìï† Ïàò ÏóÜÏäµÎãàÎã§."
            }
    
    async def _generate_exploration_query(self, uncertainty: Dict, original_query: str) -> str:
        """Î∂àÌôïÏã§ÏÑ±Ïóê Îî∞Î•∏ ÌÉêÏÉâ ÏøºÎ¶¨ ÏÉùÏÑ±"""
        uncertainty_type = uncertainty.get("type", "unknown")
        description = uncertainty.get("description", "")
        
        # Ïù¥ÎØ∏ Ï†úÍ≥µÎêú ÌÉêÏÉâ ÏøºÎ¶¨Í∞Ä ÏûàÏúºÎ©¥ ÏÇ¨Ïö©
        if uncertainty.get("exploration_query"):
            return uncertainty["exploration_query"]
        
        # Îç∞Ïù¥ÌÑ∞ÏÖã Í≤ΩÎ°ú Ï†ïÎ≥¥ Ï∂îÍ∞Ä
        dataset_info = ""
        if bq_client.full_dataset_path:
            dataset_info = f"""
        **Îç∞Ïù¥ÌÑ∞ÏÖã Í≤ΩÎ°ú Ï†ïÎ≥¥:**
        - Í∏∞Î≥∏ Í≤ΩÎ°ú: {bq_client.full_dataset_path}
        - ÌÖåÏù¥Î∏î Í≤ΩÎ°ú: `{bq_client.full_dataset_path}.table_name`
        - INFORMATION_SCHEMA: `{bq_client.full_dataset_path}.INFORMATION_SCHEMA.TABLES/COLUMNS`
        """
        
        # ÏûêÎèô ÌÉêÏÉâ ÏøºÎ¶¨ ÏÉùÏÑ±
        prompt = f"""
    üö® **Ï§ëÏöî: BigQuery Standard SQLÎßå ÏÇ¨Ïö©ÌïòÏÑ∏Ïöî! MySQL/PostgreSQL Î¨∏Î≤ï Ï†àÎåÄ Í∏àÏßÄ!**
    
    Î∂àÌôïÏã§ÏÑ± Ï†ïÎ≥¥:
    - ÌÉÄÏûÖ: {uncertainty_type}
    - ÏÑ§Î™Ö: {description}
    - ÏõêÎ≥∏ ÏøºÎ¶¨: {original_query}
    
    {dataset_info}
    
    **BigQuery ÌÉêÏÉâ ÏøºÎ¶¨ ÏÉùÏÑ± Í∑úÏπô (100% Ï§ÄÏàò ÌïÑÏàò):**
    
    ‚úÖ **ÌóàÏö©ÎêòÎäî BigQuery Î¨∏Î≤ï:**
    - SELECT, FROM, WHERE, GROUP BY, ORDER BY, LIMIT
    - INFORMATION_SCHEMA.TABLES, INFORMATION_SCHEMA.COLUMNS
    - Î∞±Ìã±ÏúºÎ°ú Í∞êÏãº ÌÖåÏù¥Î∏îÎ™Ö: `project.dataset.table`
    - LIMIT 20 (MySQLÏùò LIMIT offset, count ÌòïÏãù Í∏àÏßÄ)
    
    ‚ùå **Ï†àÎåÄ Í∏àÏßÄÎêú MySQL Î¨∏Î≤ï:**
    - DESCRIBE table_name (‚Üí SELECT * FROM INFORMATION_SCHEMA.COLUMNS ÏÇ¨Ïö©)
    - SHOW TABLES (‚Üí SELECT table_name FROM INFORMATION_SCHEMA.TABLES ÏÇ¨Ïö©)
    - SHOW COLUMNS (‚Üí SELECT column_name FROM INFORMATION_SCHEMA.COLUMNS ÏÇ¨Ïö©)
    - Î∞±Ìã± ÏóÜÎäî ÌÖåÏù¥Î∏îÎ™Ö
    - LIMIT offset, count ÌòïÏãù
    
    **Î∂àÌôïÏã§ÏÑ± ÌÉÄÏûÖÎ≥Ñ BigQuery ÌÉêÏÉâ ÏøºÎ¶¨:**
    
    1. **column_values** (Ïª¨Îüº Í∞í ÌÉêÏÉâ):
    ```sql
    SELECT column_name, COUNT(*) as count 
    FROM `{bq_client.full_dataset_path}.table_name` 
    GROUP BY column_name 
    ORDER BY count DESC 
    LIMIT 20
    ```
    
    2. **table_relationship** (ÌÖåÏù¥Î∏î Í¥ÄÍ≥Ñ ÌÉêÏÉâ):
    ```sql
    SELECT table_name, column_name 
    FROM `{bq_client.full_dataset_path}.INFORMATION_SCHEMA.COLUMNS` 
    WHERE table_name IN ('table1', 'table2') 
    ORDER BY table_name, column_name
    ```
    
    3. **data_range** (Îç∞Ïù¥ÌÑ∞ Î≤îÏúÑ ÌôïÏù∏):
    ```sql
    SELECT 
        MIN(column_name) as min_value,
        MAX(column_name) as max_value,
        COUNT(*) as total_count
    FROM `{bq_client.full_dataset_path}.table_name`
    ```
    
    4. **schema_ambiguity** (Ïä§ÌÇ§Îßà Î™®Ìò∏ÏÑ± Ìï¥Í≤∞):
    ```sql
    SELECT table_name, column_name, data_type 
    FROM `{bq_client.full_dataset_path}.INFORMATION_SCHEMA.COLUMNS` 
    WHERE table_name = 'specific_table_name'
    ORDER BY ordinal_position
    ```
    
    **ÏµúÏ¢Ö Í≤ÄÏ¶ù Ï≤¥ÌÅ¨Î¶¨Ïä§Ìä∏:**
    - [ ] MySQL Î¨∏Î≤ï ÏÇ¨Ïö© ÏïàÌï® (DESCRIBE, SHOW Îì±)
    - [ ] Î∞±Ìã±ÏúºÎ°ú ÌÖåÏù¥Î∏îÎ™Ö Í∞êÏåà
    - [ ] BigQuery Standard SQLÎßå ÏÇ¨Ïö©
    - [ ] LIMIT 20 Ïù¥Ìïò ÏÇ¨Ïö©
    - [ ] INFORMATION_SCHEMA ÏÇ¨Ïö© (ÌïÑÏöîÏãú)
    
    ÏúÑ Í∑úÏπôÏùÑ 100% Ï§ÄÏàòÌïòÏó¨ BigQuery ÌÉêÏÉâ ÏøºÎ¶¨Î•º ÏÉùÏÑ±Ìï¥Ï£ºÏÑ∏Ïöî.
    """
        
        try:
            response_content = await self.send_llm_request(prompt)
            return self._clean_sql_response(response_content)
        except Exception as e:
            logger.error(f"Exploration query generation failed: {str(e)}")
            return ""
    
    async def _analyze_exploration_result(self, uncertainty: Dict, query_result: Dict) -> str:
        """ÌÉêÏÉâ Í≤∞Í≥º Î∂ÑÏÑù Î∞è Ïù∏ÏÇ¨Ïù¥Ìä∏ ÏÉùÏÑ±"""
        uncertainty_type = uncertainty.get("type", "unknown")
        results = query_result.get("results", [])
        total_rows = query_result.get("total_rows", 0)
        
        if not results:
            return f"{uncertainty_type} ÌÉêÏÉâ Í≤∞Í≥ºÍ∞Ä ÎπÑÏñ¥ÏûàÏäµÎãàÎã§. Îç∞Ïù¥ÌÑ∞Í∞Ä Ï°¥Ïû¨ÌïòÏßÄ ÏïäÍ±∞ÎÇò Ï°∞Í±¥ÏùÑ ÎßåÏ°±ÌïòÎäî Î†àÏΩîÎìúÍ∞Ä ÏóÜÏäµÎãàÎã§."
        
        # Í≤∞Í≥º Î∂ÑÏÑù ÌîÑÎ°¨ÌîÑÌä∏
        results_summary = json.dumps(results[:5], ensure_ascii=False, indent=2)  # ÏÉÅÏúÑ 5Í∞úÎßå
        
        prompt = f"""
        ÌÉêÏÉâ Í≤∞Í≥º Î∂ÑÏÑù:
        - Î∂àÌôïÏã§ÏÑ± ÌÉÄÏûÖ: {uncertainty_type}
        - Ï¥ù Í≤∞Í≥º Ïàò: {total_rows}
        - ÏÉòÌîå Îç∞Ïù¥ÌÑ∞:
        {results_summary}
        
        Ïù¥ ÌÉêÏÉâ Í≤∞Í≥ºÎ•º Î∞îÌÉïÏúºÎ°ú Îã§ÏùåÏùÑ Ï†úÍ≥µÌï¥Ï£ºÏÑ∏Ïöî:
        1. Î∞úÍ≤¨Îêú Ï£ºÏöî Ïù∏ÏÇ¨Ïù¥Ìä∏
        2. Î∂àÌôïÏã§ÏÑ± Ìï¥Í≤∞ Î∞©Ïïà
        3. SQL ÏÉùÏÑ± Ïãú ÌôúÏö©Ìï† Ïàò ÏûàÎäî Íµ¨Ï≤¥Ï†Å Ï†ïÎ≥¥
        
        Í∞ÑÍ≤∞ÌïòÍ≥† Ïã§Ïö©Ï†ÅÏù∏ Ìïú Î¨∏Ïû•ÏúºÎ°ú ÏöîÏïΩÌï¥Ï£ºÏÑ∏Ïöî.
        """
        
        try:
            response_content = await self.send_llm_request(prompt)
            return response_content.strip()
        except Exception as e:
            logger.warning(f"Insight generation failed: {str(e)}")
            return f"{uncertainty_type} ÌÉêÏÉâÏóêÏÑú {total_rows}Í∞ú Í≤∞Í≥ºÎ•º Î∞úÍ≤¨ÌñàÏäµÎãàÎã§."
    
    async def _data_discovery(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """ÏùºÎ∞òÏ†ÅÏù∏ Îç∞Ïù¥ÌÑ∞ Î∞úÍ≤¨ ÌÉêÏÉâ"""
        query = input_data.get("query", "")
        tables = input_data.get("tables", [])
        
        logger.info("DataExplorer: General data discovery started")
        
        discovery_results = {
            "exploration_type": "data_discovery",
            "discoveries": [],
            "table_insights": [],
            "recommendations": []
        }
        
        # ÌÖåÏù¥Î∏îÎ≥Ñ Í∏∞Î≥∏ Ï†ïÎ≥¥ ÌÉêÏÉâ
        for table in tables[:3]:  # ÏµúÎåÄ 3Í∞ú ÌÖåÏù¥Î∏î
            table_insight = await self._discover_table_structure(table)
            discovery_results["table_insights"].append(table_insight)
        
        return discovery_results
    
    async def _discover_table_structure(self, table_name: str) -> Dict[str, Any]:
        """ÌÖåÏù¥Î∏î Íµ¨Ï°∞ Î∞úÍ≤¨"""
        # BigQuery Î¨∏Î≤ïÏúºÎ°ú Íµ¨Ï°∞ ÌÉêÏÉâ ÏøºÎ¶¨ ÏÉùÏÑ±
        # ÌÖåÏù¥Î∏îÎ™ÖÏóê Î∞±Ìã± Ï∂îÍ∞Ä (ÌîÑÎ°úÏ†ùÌä∏.Îç∞Ïù¥ÌÑ∞ÏÖã Í≤ΩÎ°ú Ìè¨Ìï®)
        full_table_name = f"`us-all-data.us_plus.{table_name}`" if not table_name.startswith('`') else table_name
        
        structure_query = f"""
        SELECT 
            COUNT(*) as total_rows
        FROM {full_table_name}
        LIMIT 1
        """
        
        try:
            result = bq_client.execute_query(structure_query, max_results=5)
            if result["success"]:
                return {
                    "table": table_name,
                    "success": True,
                    "structure_info": result["results"],
                    "insight": f"{table_name} ÌÖåÏù¥Î∏îÏùò Í∏∞Î≥∏ Íµ¨Ï°∞Î•º ÌååÏïÖÌñàÏäµÎãàÎã§."
                }
            else:
                return {
                    "table": table_name,
                    "success": False,
                    "error": result["error"]
                }
        except Exception as e:
            return {
                "table": table_name,
                "success": False,
                "error": str(e)
            }
    
    async def _relationship_analysis(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """ÌÖåÏù¥Î∏î Í∞Ñ Í¥ÄÍ≥Ñ Î∂ÑÏÑù"""
        logger.info("DataExplorer: ÌÖåÏù¥Î∏îÍ∞Ñ Í¥ÄÍ≥Ñ Î∂ÑÏÑù")
        
        # Í¥ÄÍ≥Ñ Î∂ÑÏÑù Î°úÏßÅ Íµ¨ÌòÑ
        return {
            "exploration_type": "relationship_analysis",
            "relationships": [],
            "join_recommendations": []
        }
    
    async def _statistical_analysis(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """ÌÜµÍ≥ÑÏ†Å Î∂ÑÏÑù"""
        logger.info("DataExplorer: ÌÜµÍ≥Ñ Î∂ÑÏÑù")
        
        # ÌÜµÍ≥Ñ Î∂ÑÏÑù Î°úÏßÅ Íµ¨ÌòÑ
        return {
            "exploration_type": "statistical_analysis",
            "statistics": [],
            "trends": []
        }
    
    def _clean_sql_response(self, response_content: str) -> str:
        """SQL ÏùëÎãµ Ï†ïÎ¶¨"""
        sql_query = response_content.strip()
        
        # ÏΩîÎìú Î∏îÎ°ù Ï†úÍ±∞
        if sql_query.startswith("```sql"):
            sql_query = sql_query[6:]
        if sql_query.startswith("```"):
            sql_query = sql_query[3:]
        if sql_query.endswith("```"):
            sql_query = sql_query[:-3]
        
        return sql_query.strip()
    
    def _calculate_resolution_confidence(self, query_result: Dict) -> float:
        """Î∂àÌôïÏã§ÏÑ± Ìï¥Í≤∞ Ïã†Î¢∞ÎèÑ Í≥ÑÏÇ∞"""
        total_rows = query_result.get("total_rows", 0)
        returned_rows = query_result.get("returned_rows", 0)
        
        if total_rows == 0:
            return 0.3  # Îç∞Ïù¥ÌÑ∞ ÏóÜÏùå
        elif returned_rows > 0:
            return min(0.9, 0.6 + (returned_rows / 20) * 0.3)  # Í≤∞Í≥º ÏûàÏùå
        else:
            return 0.5  # Í≤∞Í≥º Ïï†Îß§Ìï®
    
    def _update_exploration_stats(self, total_explorations: int, successful: int, processing_time: float):
        """ÌÉêÏÉâ ÌÜµÍ≥Ñ ÏóÖÎç∞Ïù¥Ìä∏"""
        self.investigation_stats["total_explorations"] += total_explorations
        self.investigation_stats["successful_explorations"] += successful
        
        if successful > 0:
            self.investigation_stats["insights_discovered"] += successful
        
        # ÌèâÍ∑† Ï≤òÎ¶¨ ÏãúÍ∞Ñ ÏóÖÎç∞Ïù¥Ìä∏
        current_avg = self.investigation_stats["avg_exploration_time"]
        total_sessions = len(self.exploration_history) + 1
        self.investigation_stats["avg_exploration_time"] = (
            (current_avg * (total_sessions - 1) + processing_time) / total_sessions
        )
        
        # Ìï¥Í≤∞Î•† ÏóÖÎç∞Ïù¥Ìä∏
        if self.investigation_stats["total_explorations"] > 0:
            self.investigation_stats["uncertainty_resolution_rate"] = (
                self.investigation_stats["successful_explorations"] / 
                self.investigation_stats["total_explorations"]
            )
    
    def get_agent_statistics(self) -> Dict[str, Any]:
        """Agent ÌÜµÍ≥Ñ Ï†ïÎ≥¥ Î∞òÌôò"""
        stats = self.investigation_stats
        
        if stats["total_explorations"] == 0:
            return {"message": "ÌÉêÏÉâ Ïù¥Î†•Ïù¥ ÏóÜÏäµÎãàÎã§."}
        
        resolution_rate = stats["uncertainty_resolution_rate"] * 100
        
        return {
            "total_explorations": stats["total_explorations"],
            "successful_explorations": stats["successful_explorations"],
            "insights_discovered": stats["insights_discovered"],
            "resolution_rate": round(resolution_rate, 2),
            "avg_exploration_time": round(stats["avg_exploration_time"], 3),
            "performance_grade": "A" if resolution_rate > 80 and stats["avg_exploration_time"] < 5.0 else "B"
        }

def _validate_bigquery_syntax(self, sql_query: str) -> bool:
    """BigQuery Î¨∏Î≤ï Í≤ÄÏ¶ù"""
    sql_upper = sql_query.upper()
    
    # Í∏àÏßÄÎêú MySQL Î¨∏Î≤ï Í≤ÄÏÇ¨
    forbidden_patterns = [
        r'\bDESCRIBE\b',
        r'\bSHOW\s+TABLES\b',
        r'\bSHOW\s+COLUMNS\b',
        r'\bUSE\b',
        r'\bCREATE\s+DATABASE\b'
    ]
    
    for pattern in forbidden_patterns:
        if re.search(pattern, sql_upper):
            return False
    
    # BigQuery ÌïÑÏàò ÏöîÏÜå Í≤ÄÏÇ¨
    if not sql_upper.startswith('SELECT'):
        return False
    
    # Î∞±Ìã±Ïù¥ ÏûàÎäîÏßÄ ÌôïÏù∏ (ÌÖåÏù¥Î∏îÎ™Ö)
    if '`' not in sql_query:
        return False
    
    return True

# Agent ÏÉùÏÑ± Ìó¨Ìçº Ìï®Ïàò
def create_data_explorer_agent(custom_config: Optional[Dict[str, Any]] = None) -> DataExplorerAgent:
    """DataExplorer Agent ÏÉùÏÑ±"""
    config = create_agent_config(
        name="data_explorer",
        specialization="data_exploration_investigation",
        model="gpt-4",
        temperature=0.2,
        max_tokens=1200,
        **(custom_config or {})
    )
    
    return DataExplorerAgent(config)