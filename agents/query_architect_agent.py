"""
QueryArchitect Agent - SQL ÏÑ§Í≥Ñ Î∞è ÏµúÏ†ÅÌôî Ï†ÑÎ¨∏ Agent

Í∏∞Ï°¥ sql_generator ÎÖ∏ÎìúÎ•º AgentÎ°ú Î≥ÄÌôòÌïòÏó¨ SQL ÏïÑÌÇ§ÌÖçÏ≤ò ÏÑ§Í≥Ñ,
ÏøºÎ¶¨ ÏµúÏ†ÅÌôî, ÏÑ±Îä• ÌäúÎãùÏóê ÌäπÌôîÎêú ÏßÄÎä•Ìòï AgentÎ°ú Íµ¨ÌòÑÌñàÏäµÎãàÎã§.
"""

from typing import Dict, Any, List, Optional
import logging
from datetime import datetime
import re

from .base_agent import BaseAgent, AgentMessage, MessageType, AgentConfig, create_agent_config
from rag.schema_retriever import schema_retriever
from db.bigquery_client import bq_client
from langchain.schema import HumanMessage, SystemMessage
import json

logger = logging.getLogger(__name__)

class QueryComplexity:
    """ÏøºÎ¶¨ Î≥µÏû°ÎèÑ Î∂ÑÎ•ò"""
    SIMPLE = "simple"           # Îã®Ïàú SELECT
    MODERATE = "moderate"       # JOIN, GROUP BY Ìè¨Ìï®
    COMPLEX = "complex"         # ÏÑúÎ∏åÏøºÎ¶¨, ÏúàÎèÑÏö∞ Ìï®Ïàò Îì±
    ADVANCED = "advanced"       # Î≥µÏû°Ìïú Î∂ÑÏÑù ÏøºÎ¶¨

class QueryArchitectAgent(BaseAgent):
    """SQL ÏÑ§Í≥Ñ Î∞è ÏµúÏ†ÅÌôî Ï†ÑÎ¨∏ Agent"""
    
    def __init__(self, config: Optional[AgentConfig] = None):
        if config is None:
            config = create_agent_config(
                name="query_architect",
                specialization="sql_design_optimization",
                model="gpt-4",
                temperature=0.1,  # Ï†ïÌôïÏÑ±Í≥º ÏùºÍ¥ÄÏÑ± Ï§ëÏãú
                max_tokens=1500
            )
        
        super().__init__(config)
        
        # SQL ÏÉùÏÑ± Ï†ÑÏö© ÏÑ§Ï†ï
        self.optimization_strategies = {
            "index_hints": "Ïù∏Îç±Ïä§ ÌôúÏö© ÏµúÏ†ÅÌôî",
            "join_optimization": "JOIN ÏàúÏÑú ÏµúÏ†ÅÌôî", 
            "subquery_optimization": "ÏÑúÎ∏åÏøºÎ¶¨ ÏµúÏ†ÅÌôî",
            "window_function": "ÏúàÎèÑÏö∞ Ìï®Ïàò ÌôúÏö©"
        }
        
        # ÏÑ±Îä• Ï∂îÏ†Å
        self.generation_history = []
        self.performance_stats = {
            "simple_queries": 0,
            "complex_queries": 0,
            "optimization_applied": 0,
            "avg_generation_time": 0.0
        }
        
        logger.info(f"QueryArchitect Agent initialized with specialization: {self.specialization}")
    
    def get_system_prompt(self) -> str:
        """SQL ÏÉùÏÑ± Ï†ÑÎ¨∏ ÏãúÏä§ÌÖú ÌîÑÎ°¨ÌîÑÌä∏"""
        return f"""
        ÎãπÏã†ÏùÄ SQL ÏÑ§Í≥Ñ Î∞è ÏµúÏ†ÅÌôî Ï†ÑÎ¨∏ AI AgentÏûÖÎãàÎã§.
        
        **Ï†ÑÎ¨∏ Î∂ÑÏïº:**
        - BigQuery SQL ÏïÑÌÇ§ÌÖçÏ≤ò ÏÑ§Í≥Ñ
        - ÏøºÎ¶¨ ÏÑ±Îä• ÏµúÏ†ÅÌôî Î∞è ÌäúÎãù
        - Î≥µÏû°Ìïú JOIN Ï†ÑÎûµ ÏàòÎ¶Ω
        - Ïù∏Îç±Ïä§ ÌôúÏö© Î∞è Ïã§Ìñâ Í≥ÑÌöç ÏµúÏ†ÅÌôî
        
        **ÌïµÏã¨ Ïó≠Ìï†:**
        1. ÏÇ¨Ïö©Ïûê ÏöîÏ≤≠ÏùÑ Ï†ïÌôïÌïú SQLÎ°ú Î≥ÄÌôò
        2. ÏÑ±Îä• ÏµúÏ†ÅÌôîÎêú ÏøºÎ¶¨ ÏÉùÏÑ±
        3. BigQuery ÌäπÌôî Î¨∏Î≤ï Î∞è Ìï®Ïàò ÌôúÏö©
        4. Ïä§ÌÇ§Îßà Ï†ïÎ≥¥ Í∏∞Î∞ò Ï†ïÌôïÌïú ÌÖåÏù¥Î∏î/Ïª¨Îüº Îß§Ìïë
        
        **SQL ÏÉùÏÑ± ÏõêÏπô:**
        - BigQuery ÌëúÏ§Ä SQL Î¨∏Î≤ï ÏÇ¨Ïö©
        - ÌÖåÏù¥Î∏îÎ™ÖÏùÄ ÏôÑÏ†ÑÌïú ÌòïÏãù (dataset.table) ÏÇ¨Ïö©
        - Ìö®Ïú®Ï†ÅÏù¥Í≥† ÏÑ±Îä•Ïù¥ Ï¢ãÏùÄ ÏøºÎ¶¨ ÏÉùÏÑ±
        - Ï†ÅÏ†àÌïú LIMIT ÏÇ¨Ïö©ÏúºÎ°ú Í≤∞Í≥º Ï†úÌïú (Í∏∞Î≥∏ 100)
        - ÎÇ†Ïßú/ÏãúÍ∞Ñ Ï≤òÎ¶¨Ïóê TIMESTAMP, DATE Ìï®Ïàò Ï†ÅÍ∑π ÌôúÏö©
        - JOINÏù¥ ÌïÑÏöîÌïú Í≤ΩÏö∞ ÏµúÏ†ÅÌôîÎêú JOIN Ï°∞Í±¥ ÏÇ¨Ïö©
        - ÏßëÍ≥Ñ Î∞è ÏúàÎèÑÏö∞ Ìï®Ïàò Ï†ÅÏ†àÌûà ÌôúÏö©
        
        **ÏÑ±Îä• ÏµúÏ†ÅÌôî Ï†ÑÎûµ:**
        - Ïù∏Îç±Ïä§ ÌôúÏö© Í∞ÄÎä•Ìïú WHERE Ï°∞Í±¥ Ïö∞ÏÑ† Î∞∞Ïπò
        - Î∂àÌïÑÏöîÌïú Ïª¨Îüº Ï°∞Ìöå ÏµúÏÜåÌôî
        - JOIN ÏàúÏÑú ÏµúÏ†ÅÌôî (ÏûëÏùÄ ÌÖåÏù¥Î∏î Î®ºÏ†Ä)
        - ÏÑúÎ∏åÏøºÎ¶¨Î≥¥Îã§ JOIN ÏÑ†Ìò∏
        - ÌååÌã∞ÏÖò Ïª¨Îüº ÌôúÏö© (ÎÇ†Ïßú Í∏∞Î∞ò)
        
        **ÌíàÏßà Î≥¥Ïû•:**
        - ÏÉùÏÑ± ÏãúÍ∞Ñ: ÌèâÍ∑† 1-3Ï¥à Î™©Ìëú
        - Ï†ïÌôïÎèÑ: 98% Ïù¥ÏÉÅ Î™©Ìëú
        - ÏÑ±Îä•: ÏµúÏ†ÅÌôî Ï†ÅÏö©Î•† 80% Ïù¥ÏÉÅ Î™©Ìëú
        """
    
    async def process_message(self, message: AgentMessage) -> AgentMessage:
        """Î©îÏãúÏßÄ Ï≤òÎ¶¨ - SQL ÏÉùÏÑ± ÏûëÏóÖ ÏàòÌñâ"""
        try:
            # ÏûÖÎ†• Ïú†Ìö®ÏÑ± Í≤ÄÏ¶ù
            if not await self.validate_input(message):
                return self.create_error_message(message, ValueError("Invalid input message"))
            
            # Î©îÏãúÏßÄ ÌûàÏä§ÌÜ†Î¶¨Ïóê Ï∂îÍ∞Ä
            self.add_message_to_history(message)
            
            # ÏûëÏóÖ ÌÉÄÏûÖÏóê Îî∞Î•∏ Ï≤òÎ¶¨
            task_type = message.content.get("task_type", "optimized_generation")
            
            if task_type == "simple_generation":
                result = await self._simple_generation(message.content)
            elif task_type == "optimized_generation":
                result = await self._optimized_generation(message.content)
            elif task_type == "draft_generation":
                result = await self._draft_generation(message.content)
            elif task_type == "final_optimization":
                result = await self._final_optimization(message.content)
            elif task_type == "execute_with_improvements":
                result = await self._execute_with_improvements(message.content)
            else:
                result = await self._optimized_generation(message.content)  # Í∏∞Î≥∏Í∞í
            
            # ÏÑ±Í≥µ ÏùëÎãµ ÏÉùÏÑ±
            return self.create_response_message(message, result)
            
        except Exception as e:
            logger.error(f"QueryArchitect Agent processing failed: {str(e)}")
            return self.create_error_message(message, e)
    
    async def _simple_generation(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """Îã®Ïàú SQL ÏÉùÏÑ± - Îπ†Î•∏ Ï≤òÎ¶¨Ïö©"""
        query = input_data.get("query", "")
        context = input_data.get("context", {})
        
        logger.info(f"QueryArchitect: Simple generation for query: '{query[:50]}...'")
        
        # Í∏∞Î≥∏ RAG Í≤ÄÏÉâ
        try:
            relevant_context = schema_retriever.create_context_summary(query, max_tables=3)
        except Exception as e:
            logger.warning(f"RAG search failed: {str(e)}")
            relevant_context = "Ïä§ÌÇ§Îßà Ï†ïÎ≥¥Î•º Í∞ÄÏ†∏Ïò¨ Ïàò ÏóÜÏäµÎãàÎã§."
        
        # Îã®Ïàú SQL ÏÉùÏÑ± ÌîÑÎ°¨ÌîÑÌä∏
        user_message = f"""
        ÏÇ¨Ïö©Ïûê ÏöîÏ≤≠: {query}
        
        Ïä§ÌÇ§Îßà Ï†ïÎ≥¥:
        {relevant_context}
        
        Îã®ÏàúÌïòÍ≥† ÏßÅÍ¥ÄÏ†ÅÏù∏ BigQuery SQL ÏøºÎ¶¨Î•º ÏÉùÏÑ±Ìï¥Ï£ºÏÑ∏Ïöî.
        Î≥µÏû°Ìïú ÏµúÏ†ÅÌôîÎäî ÏÉùÎûµÌïòÍ≥† Í∏∞Î≥∏Ï†ÅÏù∏ Í∏∞Îä•Îßå Íµ¨ÌòÑÌïòÏÑ∏Ïöî.
        
        SQL ÏøºÎ¶¨Îßå Î∞òÌôòÌïòÏÑ∏Ïöî.
        """
        
        try:
            start_time = datetime.now()
            response_content = await self.send_llm_request(user_message)
            processing_time = (datetime.now() - start_time).total_seconds()
            
            # SQL Ï†ïÎ¶¨
            sql_query = self._clean_sql_response(response_content)
            
            # ÌÜµÍ≥Ñ ÏóÖÎç∞Ïù¥Ìä∏
            self.performance_stats["simple_queries"] += 1
            self._update_generation_stats(processing_time)
            
            result = {
                "generation_type": "simple_generation",
                "sql_query": sql_query,
                "processing_time": processing_time,
                "complexity": QueryComplexity.SIMPLE,
                "optimization_applied": False,
                "schema_context_used": relevant_context is not None
            }
            
            # ÏÉùÏÑ± ÌûàÏä§ÌÜ†Î¶¨Ïóê Ï∂îÍ∞Ä
            self._add_to_generation_history(query, result)
            
            logger.info(f"Simple generation completed in {processing_time:.2f}s")
            return result
            
        except Exception as e:
            logger.error(f"Simple generation failed: {str(e)}")
            return self._create_fallback_result("simple_generation", str(e))
    
    async def _optimized_generation(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """ÏµúÏ†ÅÌôîÎêú SQL ÏÉùÏÑ± - ÌëúÏ§Ä Ï≤òÎ¶¨"""
        query = input_data.get("query", "")
        analysis_result = input_data.get("analysis_result", {})
        exploration_result = input_data.get("exploration_result", {})
        
        logger.info(f"QueryArchitect: Optimized generation started")
        
        # ÌôïÏû•Îêú RAG Í≤ÄÏÉâ
        try:
            relevant_context = schema_retriever.create_context_summary(query, max_tables=5)
        except Exception as e:
            logger.warning(f"Extended RAG search failed: {str(e)}")
            relevant_context = "Ïä§ÌÇ§Îßà Ï†ïÎ≥¥Î•º Í∞ÄÏ†∏Ïò¨ Ïàò ÏóÜÏäµÎãàÎã§."
        
        # ÌÉêÏÉâ Í≤∞Í≥º Ïª®ÌÖçÏä§Ìä∏ ÏÉùÏÑ±
        exploration_context = self._build_exploration_context(exploration_result)
        
        # Î∂ÑÏÑù Í≤∞Í≥º Ïª®ÌÖçÏä§Ìä∏ ÏÉùÏÑ±
        analysis_context = self._build_analysis_context(analysis_result)
        
        # ÏµúÏ†ÅÌôîÎêú SQL ÏÉùÏÑ± ÌîÑÎ°¨ÌîÑÌä∏
        user_message = f"""
        ÏÇ¨Ïö©Ïûê ÏöîÏ≤≠: {query}
        
        Ïä§ÌÇ§Îßà Ï†ïÎ≥¥:
        {relevant_context}
        
        {analysis_context}
        
        {exploration_context}
        
        ÏúÑ Ï†ïÎ≥¥Î•º Ï¢ÖÌï©ÌïòÏó¨ ÏÑ±Îä• ÏµúÏ†ÅÌôîÎêú BigQuery SQL ÏøºÎ¶¨Î•º ÏÉùÏÑ±Ìï¥Ï£ºÏÑ∏Ïöî.
        
        ÏµúÏ†ÅÌôî Í≥†Î†§ÏÇ¨Ìï≠:
        1. Ïù∏Îç±Ïä§ ÌôúÏö© Í∞ÄÎä•Ìïú WHERE Ï°∞Í±¥ Î∞∞Ïπò
        2. Ï†ÅÏ†àÌïú JOIN ÏàúÏÑú (ÏûëÏùÄ ÌÖåÏù¥Î∏î Î®ºÏ†Ä)
        3. Î∂àÌïÑÏöîÌïú Ïª¨Îüº Ï°∞Ìöå ÏµúÏÜåÌôî
        4. ÌååÌã∞ÏÖò Ïª¨Îüº ÌôúÏö© (ÎÇ†Ïßú Í∏∞Î∞ò)
        5. LIMIT ÏÇ¨Ïö©ÏúºÎ°ú Í≤∞Í≥º Ï†úÌïú
        
        SQL ÏøºÎ¶¨Îßå Î∞òÌôòÌïòÏÑ∏Ïöî.
        """
        
        try:
            start_time = datetime.now()
            response_content = await self.send_llm_request(user_message)
            processing_time = (datetime.now() - start_time).total_seconds()
            
            # SQL Ï†ïÎ¶¨ Î∞è Í≤ÄÏ¶ù
            sql_query = self._clean_sql_response(response_content)
            complexity = self._assess_query_complexity(sql_query)
            optimizations = self._detect_applied_optimizations(sql_query)
            
            # ÌÜµÍ≥Ñ ÏóÖÎç∞Ïù¥Ìä∏
            if complexity in [QueryComplexity.COMPLEX, QueryComplexity.ADVANCED]:
                self.performance_stats["complex_queries"] += 1
            if optimizations:
                self.performance_stats["optimization_applied"] += 1
            
            self._update_generation_stats(processing_time)
            
            result = {
                "generation_type": "optimized_generation",
                "sql_query": sql_query,
                "processing_time": processing_time,
                "complexity": complexity,
                "optimization_applied": len(optimizations) > 0,
                "applied_optimizations": optimizations,
                "schema_context_used": relevant_context is not None,
                "exploration_used": bool(exploration_result),
                "confidence": self._calculate_confidence(sql_query, analysis_result)
            }
            
            # ÏÉùÏÑ± ÌûàÏä§ÌÜ†Î¶¨Ïóê Ï∂îÍ∞Ä
            self._add_to_generation_history(query, result)
            
            logger.info(f"Optimized generation completed in {processing_time:.2f}s")
            return result
            
        except Exception as e:
            logger.error(f"Optimized generation failed: {str(e)}")
            return self._create_fallback_result("optimized_generation", str(e))
    
    async def _draft_generation(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """Ï¥àÏïà ÏÉùÏÑ± - Î≥µÏû°Ìïú ÏøºÎ¶¨Ïö©"""
        query = input_data.get("query", "")
        analysis_result = input_data.get("analysis_result", {})
        
        logger.info("QueryArchitect: Draft generation for complex query")
        
        # Îã§Îã®Í≥Ñ Ï†ëÍ∑ºÎ≤ï
        # 1Îã®Í≥Ñ: Í∏∞Î≥∏ Íµ¨Ï°∞ ÏÉùÏÑ±
        basic_structure = await self._generate_basic_structure(query, analysis_result)
        
        # 2Îã®Í≥Ñ: JOIN Î∞è Í¥ÄÍ≥Ñ Ï∂îÍ∞Ä
        with_relationships = await self._add_table_relationships(basic_structure, analysis_result)
        
        # 3Îã®Í≥Ñ: Ï°∞Í±¥ Î∞è ÌïÑÌÑ∞ Ï∂îÍ∞Ä
        complete_draft = await self._add_conditions_and_filters(with_relationships, query)
        
        result = {
            "generation_type": "draft_generation",
            "sql_query": complete_draft,
            "processing_stages": ["basic_structure", "relationships", "conditions"],
            "complexity": QueryComplexity.COMPLEX,
            "requires_review": True
        }
        
        return result
    
    async def _final_optimization(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """ÏµúÏ¢Ö ÏµúÏ†ÅÌôî - Í≤ÄÌÜ† ÌõÑ Í∞úÏÑ†"""
        draft_sql = input_data.get("draft_sql", "")
        feedback = input_data.get("feedback", {})
        
        logger.info("QueryArchitect: Final optimization started")
        
        # ÌîºÎìúÎ∞± Í∏∞Î∞ò Í∞úÏÑ†
        optimization_prompt = f"""
        Ï¥àÏïà SQL: {draft_sql}
        
        Í≤ÄÌÜ† ÌîºÎìúÎ∞±: {feedback}
        
        ÌîºÎìúÎ∞±ÏùÑ Î∞òÏòÅÌïòÏó¨ SQLÏùÑ ÏµúÏ†ÅÌôîÌï¥Ï£ºÏÑ∏Ïöî.
        ÌäπÌûà ÏÑ±Îä•, Ï†ïÌôïÏÑ±, Í∞ÄÎèÖÏÑ±ÏùÑ Í∞úÏÑ†Ìï¥Ï£ºÏÑ∏Ïöî.
        
        ÏµúÏ†ÅÌôîÎêú SQL ÏøºÎ¶¨Îßå Î∞òÌôòÌïòÏÑ∏Ïöî.
        """
        
        try:
            response_content = await self.send_llm_request(optimization_prompt)
            optimized_sql = self._clean_sql_response(response_content)
            
            result = {
                "generation_type": "final_optimization",
                "sql_query": optimized_sql,
                "original_sql": draft_sql,
                "feedback_applied": feedback,
                "optimization_complete": True
            }
            
            return result
            
        except Exception as e:
            logger.error(f"Final optimization failed: {str(e)}")
            return {"generation_type": "final_optimization", "sql_query": draft_sql, "error": str(e)}
    
    def _build_exploration_context(self, exploration_result: Dict) -> str:
        """ÌÉêÏÉâ Í≤∞Í≥ºÎ•º Ïª®ÌÖçÏä§Ìä∏Î°ú Î≥ÄÌôò"""
        if not exploration_result or not exploration_result.get("insights"):
            return ""
        
        insights = exploration_result.get("insights", [])
        return f"""
=== ÌÉêÏÉâÏùÑ ÌÜµÌï¥ Î∞úÍ≤¨Îêú Ï†ïÎ≥¥ ===
{chr(10).join([f"- {insight}" for insight in insights])}

Ïù¥ Ï†ïÎ≥¥Î•º Î∞îÌÉïÏúºÎ°ú Îçî Ï†ïÌôïÌïú SQL ÏøºÎ¶¨Î•º ÏÉùÏÑ±ÌïòÏÑ∏Ïöî.
        """
    
    def _build_analysis_context(self, analysis_result: Dict) -> str:
        """Î∂ÑÏÑù Í≤∞Í≥ºÎ•º Ïª®ÌÖçÏä§Ìä∏Î°ú Î≥ÄÌôò"""
        if not analysis_result:
            return ""
        
        uncertainties = analysis_result.get("uncertainties", [])
        if not uncertainties:
            return ""
        
        context = "=== Î∂àÌôïÏã§ÏÑ± Î∂ÑÏÑù Í≤∞Í≥º ===\n"
        for uncertainty in uncertainties:
            context += f"- {uncertainty.get('type', 'unknown')}: {uncertainty.get('description', 'N/A')}\n"
        
        context += "\nÏù¥Îü¨Ìïú Î∂àÌôïÏã§ÏÑ±ÏùÑ Í≥†Î†§ÌïòÏó¨ Ï†ÅÏ†àÌïú Í∞ÄÏ†ïÏùÑ ÏÑ∏Ïö∞Í≥† SQLÏùÑ ÏÉùÏÑ±Ìï¥Ï£ºÏÑ∏Ïöî.\n"
        return context
    
    def _clean_sql_response(self, response_content: str) -> str:
        """SQL ÏùëÎãµ Ï†ïÎ¶¨"""
        sql_query = response_content.strip()
        
        # ÏΩîÎìú Î∏îÎ°ù Ï†úÍ±∞
        if sql_query.startswith("```sql"):
            sql_query = sql_query[6:]
        if sql_query.startswith("```"):
            sql_query = sql_query[3:]
        if sql_query.endswith("```"):
            sql_query = sql_query[:-3]
        
        return sql_query.strip()
    
    def _assess_query_complexity(self, sql_query: str) -> str:
        """ÏøºÎ¶¨ Î≥µÏû°ÎèÑ ÌèâÍ∞Ä"""
        sql_lower = sql_query.lower()
        
        # Í≥†Í∏â Í∏∞Îä• Í≤ÄÏ∂ú
        advanced_patterns = ["window", "partition by", "row_number", "rank", "cte", "with recursive"]
        if any(pattern in sql_lower for pattern in advanced_patterns):
            return QueryComplexity.ADVANCED
        
        # Î≥µÏû°Ìïú Í∏∞Îä• Í≤ÄÏ∂ú
        complex_patterns = ["subquery", "exists", "case when", "union", "having"]
        subquery_count = len(re.findall(r'\bselect\b', sql_lower)) - 1
        if subquery_count > 0 or any(pattern in sql_lower for pattern in complex_patterns):
            return QueryComplexity.COMPLEX
        
        # Ï§ëÍ∞Ñ Î≥µÏû°ÎèÑ Í≤ÄÏ∂ú
        moderate_patterns = ["join", "group by", "order by", "distinct"]
        if any(pattern in sql_lower for pattern in moderate_patterns):
            return QueryComplexity.MODERATE
        
        return QueryComplexity.SIMPLE
    
    def _detect_applied_optimizations(self, sql_query: str) -> List[str]:
        """Ï†ÅÏö©Îêú ÏµúÏ†ÅÌôî Í∏∞Î≤ï ÌÉêÏßÄ"""
        optimizations = []
        sql_lower = sql_query.lower()
        
        if "limit" in sql_lower:
            optimizations.append("result_limiting")
        
        if "where" in sql_lower and ("=" in sql_lower or "in" in sql_lower):
            optimizations.append("indexed_filtering")
        
        if "join" in sql_lower:
            optimizations.append("join_optimization")
        
        if any(pattern in sql_lower for pattern in ["timestamp", "date", "datetime"]):
            optimizations.append("temporal_optimization")
        
        return optimizations
    
    def _calculate_confidence(self, sql_query: str, analysis_result: Dict) -> float:
        """ÏÉùÏÑ±Îêú SQLÏùò Ïã†Î¢∞ÎèÑ Í≥ÑÏÇ∞"""
        confidence = 0.8  # Í∏∞Î≥∏ Ïã†Î¢∞ÎèÑ
        
        # Ïä§ÌÇ§Îßà Ï†ïÎ≥¥ ÌôúÏö© Ïó¨Î∂Ä
        if bq_client.schema_info:
            confidence += 0.1
        
        # Î∂àÌôïÏã§ÏÑ± Ìï¥Í≤∞ Ïó¨Î∂Ä
        uncertainties = analysis_result.get("uncertainties", []) if analysis_result else []
        if not uncertainties:
            confidence += 0.1
        elif len(uncertainties) > 3:
            confidence -= 0.2
        
        # SQL Î≥µÏû°ÎèÑÏóê Îî∞Î•∏ Ï°∞Ï†ï
        complexity = self._assess_query_complexity(sql_query)
        if complexity == QueryComplexity.SIMPLE:
            confidence += 0.05
        elif complexity == QueryComplexity.ADVANCED:
            confidence -= 0.1
        
        return min(max(confidence, 0.0), 1.0)
    
    async def _generate_basic_structure(self, query: str, analysis: Dict) -> str:
        """Í∏∞Î≥∏ SQL Íµ¨Ï°∞ ÏÉùÏÑ±"""
        prompt = f"""
        ÏÇ¨Ïö©Ïûê ÏöîÏ≤≠: {query}
        
        Í∏∞Î≥∏Ï†ÅÏù∏ SELECT Íµ¨Ï°∞Îßå ÏÉùÏÑ±Ìï¥Ï£ºÏÑ∏Ïöî.
        Î≥µÏû°Ìïú JOINÏù¥ÎÇò Ï°∞Í±¥ÏùÄ Ï†úÏô∏ÌïòÍ≥† ÌïµÏã¨ ÌÖåÏù¥Î∏îÍ≥º Ïª¨ÎüºÎßå Ìè¨Ìï®ÌïòÏÑ∏Ïöî.
        
        SQL ÏøºÎ¶¨Îßå Î∞òÌôòÌïòÏÑ∏Ïöî.
        """
        
        response = await self.send_llm_request(prompt)
        return self._clean_sql_response(response)
    
    async def _add_table_relationships(self, basic_sql: str, analysis: Dict) -> str:
        """ÌÖåÏù¥Î∏î Í¥ÄÍ≥Ñ Ï∂îÍ∞Ä"""
        prompt = f"""
        Í∏∞Î≥∏ SQL: {basic_sql}
        
        ÌïÑÏöîÌïú JOINÏùÑ Ï∂îÍ∞ÄÌï¥Ï£ºÏÑ∏Ïöî.
        ÌÖåÏù¥Î∏î Í∞Ñ Í¥ÄÍ≥ÑÎ•º Ï†ïÌôïÌûà ÌååÏïÖÌïòÏó¨ Ï†ÅÏ†àÌïú JOIN Ï°∞Í±¥ÏùÑ ÏÑ§Ï†ïÌïòÏÑ∏Ïöî.
        
        Í∞úÏÑ†Îêú SQL ÏøºÎ¶¨Îßå Î∞òÌôòÌïòÏÑ∏Ïöî.
        """
        
        response = await self.send_llm_request(prompt)
        return self._clean_sql_response(response)
    
    async def _add_conditions_and_filters(self, sql_with_joins: str, original_query: str) -> str:
        """Ï°∞Í±¥ Î∞è ÌïÑÌÑ∞ Ï∂îÍ∞Ä"""
        prompt = f"""
        ÌòÑÏû¨ SQL: {sql_with_joins}
        ÏõêÎ≥∏ ÏöîÏ≤≠: {original_query}
        
        ÏÇ¨Ïö©Ïûê ÏöîÏ≤≠Ïóê ÎßûÎäî WHERE Ï°∞Í±¥, ORDER BY, LIMIT Îì±ÏùÑ Ï∂îÍ∞ÄÌï¥Ï£ºÏÑ∏Ïöî.
        
        ÏôÑÏÑ±Îêú SQL ÏøºÎ¶¨Îßå Î∞òÌôòÌïòÏÑ∏Ïöî.
        """
        
        response = await self.send_llm_request(prompt)
        return self._clean_sql_response(response)
    
    async def _execute_with_improvements(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """SQL Ïã§Ìñâ Î∞è Ïã§Ìå®Ïãú Í∞úÏÑ†Î∞©Ïïà Ï¶âÏãú Ï†ÅÏö©"""
        sql_query = input_data.get("sql_query", "")
        original_query = input_data.get("original_query", "")
        
        logger.info("QueryArchitect: Execute with improvements started")
        
        if not sql_query:
            return {
                "execution_type": "execute_with_improvements",
                "success": False,
                "error": "Ïã§ÌñâÌï† SQL ÏøºÎ¶¨Í∞Ä ÏóÜÏäµÎãàÎã§.",
                "sql_query": sql_query
            }
        
        start_time = datetime.now()
        
        # 1Îã®Í≥Ñ: ÏõêÎ≥∏ SQL Ïã§Ìñâ ÏãúÎèÑ
        print(f"üîÑ SQL Ïã§Ìñâ Ï§ë...")
        print(f"üìù SQL: {sql_query}")
        
        try:
            query_result = bq_client.execute_query(sql_query)
            processing_time = (datetime.now() - start_time).total_seconds()
            
            if query_result["success"]:
                # ÏÑ±Í≥µÏãú Î∞îÎ°ú Î∞òÌôò
                print(f"‚úÖ SQL Ïã§Ìñâ ÏÑ±Í≥µ! ({processing_time:.2f}Ï¥à)")
                print(f"üìä Í≤∞Í≥º: {query_result['returned_rows']}Í∞ú Ìñâ Î∞òÌôò")
                
                return {
                    "execution_type": "execute_with_improvements",
                    "success": True,
                    "sql_query": sql_query,
                    "query_result": query_result,
                    "processing_time": processing_time,
                    "improvements_applied": False
                }
            
            # 2Îã®Í≥Ñ: Ïã§Ìå®Ïãú Í∞úÏÑ†Î∞©Ïïà ÏÉùÏÑ±
            print(f"‚ùå SQL Ïã§Ìñâ Ïã§Ìå®: {query_result.get('error', 'Unknown error')}")
            print("üîß Í∞úÏÑ†Î∞©Ïïà ÏÉùÏÑ± Ï§ë...")
            
            improvements = await self._generate_sql_improvements(sql_query, query_result.get('error', ''), original_query)
            
            if not improvements:
                return {
                    "execution_type": "execute_with_improvements", 
                    "success": False,
                    "sql_query": sql_query,
                    "error": query_result.get('error', ''),
                    "improvements_generated": False
                }
            
            # 3Îã®Í≥Ñ: Í∞úÏÑ†Î∞©Ïïà Ï∂úÎ†• Î∞è ÏÇ¨Ïö©Ïûê ÌôïÏù∏
            print("\nüõ†Ô∏è Ï†úÏïàÎêú Í∞úÏÑ†Î∞©Ïïà:")
            for i, improvement in enumerate(improvements, 1):
                print(f"{i}. {improvement['description']}")
                if improvement.get('improved_sql'):
                    print(f"   Í∞úÏÑ†Îêú SQL: {improvement['improved_sql'][:100]}...")
            
            # 4Îã®Í≥Ñ: ÏûêÎèô Ïã§Ìñâ (Í∞ÄÏû• Ïã†Î¢∞ÎèÑ ÎÜíÏùÄ Í∞úÏÑ†Ïïà)
            best_improvement = max(improvements, key=lambda x: x.get('confidence', 0))
            
            if best_improvement.get('confidence', 0) > 0.7:
                print(f"\nüöÄ Ïã†Î¢∞ÎèÑ ÎÜíÏùÄ Í∞úÏÑ†ÏïàÏùÑ ÏûêÎèô Ïã§ÌñâÌï©ÎãàÎã§. (Ïã†Î¢∞ÎèÑ: {best_improvement['confidence']:.2f})")
                return await self._execute_improved_sql(best_improvement, start_time)
            else:
                # Ïã†Î¢∞ÎèÑÍ∞Ä ÎÇÆÏúºÎ©¥ ÏÇ¨Ïö©Ïûê ÌôïÏù∏ ÏöîÏ≤≠
                if await self._ask_user_confirmation_async():
                    return await self._execute_improved_sql(best_improvement, start_time)
                else:
                    print("‚ùå ÏÇ¨Ïö©ÏûêÍ∞Ä Í∞úÏÑ†Î∞©Ïïà Ïã§ÌñâÏùÑ Ï∑®ÏÜåÌñàÏäµÎãàÎã§.")
                    return {
                        "execution_type": "execute_with_improvements",
                        "success": False,
                        "sql_query": sql_query,
                        "error": query_result.get('error', ''),
                        "improvements_generated": True,
                        "improvements_applied": False,
                        "user_cancelled": True
                    }
            
        except Exception as e:
            processing_time = (datetime.now() - start_time).total_seconds()
            logger.error(f"Execute with improvements failed: {str(e)}")
            return {
                "execution_type": "execute_with_improvements",
                "success": False,
                "sql_query": sql_query,
                "error": str(e),
                "processing_time": processing_time
            }
    
    async def _generate_sql_improvements(self, sql_query: str, error_message: str, original_query: str) -> List[Dict[str, Any]]:
        """SQL Ïò§Î•ò Î∂ÑÏÑù Î∞è Í∞úÏÑ†Î∞©Ïïà ÏÉùÏÑ±"""
        
        # Ïä§ÌÇ§Îßà Ï†ïÎ≥¥ Ï§ÄÎπÑ
        schema_context = self._build_schema_context_for_improvement(sql_query)
        
        system_prompt = f"""
        ÎãπÏã†ÏùÄ BigQuery SQL Ïò§Î•ò Î∂ÑÏÑù Î∞è Í∞úÏÑ† Ï†ÑÎ¨∏Í∞ÄÏûÖÎãàÎã§.
        
        **Î∂ÑÏÑùÌï† Ï†ïÎ≥¥:**
        - ÏõêÎ≥∏ ÏÇ¨Ïö©Ïûê ÏöîÏ≤≠: {original_query}
        - Ïã§Ìå®Ìïú SQL: {sql_query}
        - Ïò§Î•ò Î©îÏãúÏßÄ: {error_message}
        
        **Ïä§ÌÇ§Îßà Ï†ïÎ≥¥:**
        {schema_context}
        
        **Í∞úÏÑ† Ï†ÑÎûµ:**
        1. Ïª¨ÎüºÎ™Ö Ïò§Î•ò: Ï†ïÌôïÌïú Ïª¨ÎüºÎ™ÖÏúºÎ°ú ÏàòÏ†ï (Ïò§Î•ò Î©îÏãúÏßÄÏùò "Did you mean" ÌôúÏö©)
        2. Îç∞Ïù¥ÌÑ∞ ÌÉÄÏûÖ Ïò§Î•ò: PARSE_TIMESTAMP, CAST Îì± Ï†ÅÏ†àÌïú ÌÉÄÏûÖ Î≥ÄÌôò
        3. ÌÖåÏù¥Î∏îÎ™Ö Ïò§Î•ò: Ïò¨Î∞îÎ•∏ dataset.table ÌòïÏãùÏúºÎ°ú ÏàòÏ†ï
        4. Î¨∏Î≤ï Ïò§Î•ò: BigQuery ÌëúÏ§Ä SQL Î¨∏Î≤ï Ï§ÄÏàò
        5. Ìï®Ïàò ÏÇ¨Ïö© Ïò§Î•ò: Ïò¨Î∞îÎ•∏ Ìï®Ïàò Î∞è ÌååÎùºÎØ∏ÌÑ∞
        
        **ÏùëÎãµ ÌòïÏãù (JSON):**
        {{
            "improvements": [
                {{
                    "issue_type": "column_name|data_type|table_name|syntax|function",
                    "description": "Íµ¨Ï≤¥Ï†ÅÏù∏ Î¨∏Ï†úÏ†êÍ≥º Ìï¥Í≤∞Ï±Ö ÏÑ§Î™Ö",
                    "improved_sql": "ÏôÑÏ†ÑÌûà ÏàòÏ†ïÎêú SQL ÏøºÎ¶¨",
                    "confidence": 0.0-1.0,
                    "changes_made": ["Î≥ÄÍ≤ΩÏÇ¨Ìï≠1", "Î≥ÄÍ≤ΩÏÇ¨Ìï≠2"]
                }}
            ]
        }}
        """
        
        try:
            response_content = await self.send_llm_request(system_prompt)
            
            # JSON ÌååÏã±
            content = response_content.strip()
            if content.startswith("```json"):
                content = content[7:]
            if content.startswith("```"):
                content = content[3:]
            if content.endswith("```"):
                content = content[:-3]
            
            improvement_data = json.loads(content.strip())
            improvements = improvement_data.get("improvements", [])
            
            # Í∏∞Î≥∏ Í∞úÏÑ†Î∞©Ïïà Ï∂îÍ∞Ä (AIÍ∞Ä ÎÜìÏπú Î∂ÄÎ∂Ñ Î≥¥ÏôÑ)
            basic_improvements = self._generate_basic_improvements(sql_query, error_message)
            improvements.extend(basic_improvements)
            
            return improvements
            
        except Exception as e:
            logger.error(f"AI improvement generation failed: {str(e)}")
            # AI Ïã§Ìå®Ïãú Í∏∞Î≥∏ Í∞úÏÑ†Î∞©ÏïàÎßå Î∞òÌôò
            return self._generate_basic_improvements(sql_query, error_message)
    
    def _generate_basic_improvements(self, sql_query: str, error_message: str) -> List[Dict[str, Any]]:
        """Í∏∞Î≥∏Ï†ÅÏù∏ Í∞úÏÑ†Î∞©Ïïà ÏÉùÏÑ± (Ìå®ÌÑ¥ Í∏∞Î∞ò)"""
        improvements = []
        
        # 1. Ïª¨ÎüºÎ™Ö Ïò§Î•ò Ï≤òÎ¶¨
        if "Unrecognized name" in error_message:
            match = re.search(r"Unrecognized name: (\w+)", error_message)
            suggestion_match = re.search(r"Did you mean (\w+)?", error_message)
            
            if match and suggestion_match:
                wrong_column = match.group(1)
                correct_column = suggestion_match.group(1)
                improved_sql = sql_query.replace(wrong_column, correct_column)
                
                improvements.append({
                    "issue_type": "column_name",
                    "description": f"Ïª¨ÎüºÎ™Ö '{wrong_column}'ÏùÑ '{correct_column}'ÏúºÎ°ú ÏàòÏ†ï",
                    "improved_sql": improved_sql,
                    "confidence": 0.95,
                    "changes_made": [f"{wrong_column} ‚Üí {correct_column}"]
                })
        
        # 2. Îç∞Ïù¥ÌÑ∞ ÌÉÄÏûÖ Ïò§Î•ò Ï≤òÎ¶¨ 
        elif "No matching signature" in error_message and ("TIMESTAMP" in error_message or "STRING" in error_message):
            if "createdAt" in sql_query:
                # createdAt Ïª¨ÎüºÏùÑ TIMESTAMPÎ°ú Î≥ÄÌôò (ISO 8601 ÌòïÏãù)
                improved_sql = re.sub(
                    r"(\w+\.)?createdAt(\s*[><=]+\s*)",
                    r"PARSE_TIMESTAMP('%Y-%m-%dT%H:%M:%E*SZ', \1createdAt)\2",
                    sql_query
                )
                
                improvements.append({
                    "issue_type": "data_type",
                    "description": "createdAt Ïª¨ÎüºÏùÑ ISO 8601 ÌòïÏãùÏùò PARSE_TIMESTAMPÎ°ú Î≥ÄÌôòÌïòÏó¨ ÎÇ†Ïßú ÎπÑÍµê Í∞ÄÎä•ÌïòÎèÑÎ°ù ÏàòÏ†ï",
                    "improved_sql": improved_sql,
                    "confidence": 0.9,
                    "changes_made": ["createdAt ‚Üí PARSE_TIMESTAMP('%Y-%m-%dT%H:%M:%E*SZ', createdAt)"]
                })
        
        # 3. Ìï®Ïàò Ïò§Î•ò Ï≤òÎ¶¨
        elif "CURRENT_DATE" in sql_query and "INTERVAL" in error_message:
            # CURRENT_DATE() ‚Üí CURRENT_TIMESTAMP()Î°ú ÏàòÏ†ï
            improved_sql = sql_query.replace("CURRENT_DATE()", "CURRENT_TIMESTAMP()")
            
            improvements.append({
                "issue_type": "function",
                "description": "ÎÇ†Ïßú Ìï®ÏàòÎ•º CURRENT_TIMESTAMP()Î°ú ÏàòÏ†ï",
                "improved_sql": improved_sql,
                "confidence": 0.8,
                "changes_made": ["CURRENT_DATE() ‚Üí CURRENT_TIMESTAMP()"]
            })
        
        return improvements
    
    def _build_schema_context_for_improvement(self, sql_query: str) -> str:
        """Í∞úÏÑ†ÏùÑ ÏúÑÌïú Ïä§ÌÇ§Îßà Ïª®ÌÖçÏä§Ìä∏ ÏÉùÏÑ±"""
        try:
            schema_info = getattr(bq_client, 'schema_info', [])
            if not schema_info:
                return "Ïä§ÌÇ§Îßà Ï†ïÎ≥¥Í∞Ä ÏóÜÏäµÎãàÎã§."
            
            # SQLÏóêÏÑú Ïñ∏Í∏âÎêú ÌÖåÏù¥Î∏î Ï∞æÍ∏∞
            mentioned_tables = []
            for table_info in schema_info:
                # schema_infoÍ∞Ä Î¨∏ÏûêÏó¥Ïù∏ Í≤ΩÏö∞ Ï≤òÎ¶¨
                if isinstance(table_info, str):
                    continue
                    
                table_name = table_info.get("table_name", "") if isinstance(table_info, dict) else ""
                if table_name and table_name.lower() in sql_query.lower():
                    mentioned_tables.append(table_info)
            
            if not mentioned_tables:
                return "Í¥ÄÎ†® ÌÖåÏù¥Î∏îÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§."
            
            context = "Í¥ÄÎ†® ÌÖåÏù¥Î∏î Ïä§ÌÇ§Îßà:\n"
            for table in mentioned_tables[:2]:  # ÏµúÎåÄ 2Í∞ú
                if not isinstance(table, dict):
                    continue
                    
                table_name = table.get("table_name", "")
                columns = table.get("columns", [])
                
                context += f"\nÌÖåÏù¥Î∏î: {table_name}\n"
                for col in columns[:8]:  # ÏµúÎåÄ 8Í∞ú Ïª¨Îüº
                    if isinstance(col, dict):
                        col_name = col.get("column_name", "")
                        col_type = col.get("data_type", "")
                        context += f"  - {col_name} ({col_type})\n"
            
            return context
            
        except Exception as e:
            logger.error(f"Schema context building failed: {str(e)}")
            return "Ïä§ÌÇ§Îßà Ï†ïÎ≥¥ Ï≤òÎ¶¨ Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§."
    
    async def _ask_user_confirmation_async(self) -> bool:
        """ÏÇ¨Ïö©Ïûê ÌôïÏù∏ (ÎπÑÎèôÍ∏∞)"""
        try:
            print("\n‚ùì Í∞úÏÑ†Îêú ÏøºÎ¶¨Î•º Ïã§ÌñâÌïòÏãúÍ≤†ÏäµÎãàÍπå?")
            print("   y/yes - Ïã§Ìñâ")
            print("   n/no - Ï∑®ÏÜå")
            
            # Ïã§Ï†ú ÌîÑÎ°úÎçïÏÖòÏóêÏÑúÎäî Ï†ÅÏ†àÌïú ÎπÑÎèôÍ∏∞ ÏûÖÎ†• Ï≤òÎ¶¨ ÌïÑÏöî
            # ÌòÑÏû¨Îäî Í∞ÑÎã®Ìïú ÎèôÍ∏∞ Ï≤òÎ¶¨
            import asyncio
            
            def get_input():
                return input("\nÏÑ†ÌÉùÌïòÏÑ∏Ïöî (y/n): ").strip().lower()
            
            response = await asyncio.get_event_loop().run_in_executor(None, get_input)
            return response in ['y', 'yes', 'Ïòà', 'ÎÑ§']
            
        except Exception as e:
            logger.error(f"User confirmation failed: {str(e)}")
            return False
    
    async def _execute_improved_sql(self, improvement: Dict, start_time: datetime) -> Dict[str, Any]:
        """Í∞úÏÑ†Îêú SQL Ïã§Ìñâ"""
        improved_sql = improvement.get('improved_sql', '')
        
        if not improved_sql:
            return {
                "execution_type": "execute_with_improvements",
                "success": False,
                "error": "Í∞úÏÑ†Îêú SQLÏù¥ ÏóÜÏäµÎãàÎã§."
            }
        
        print(f"\nüîÑ Í∞úÏÑ†Îêú ÏøºÎ¶¨ Ïã§Ìñâ Ï§ë...")
        print(f"üìù Í∞úÏÑ†Îêú SQL: {improved_sql}")
        print(f"üõ†Ô∏è Ï†ÅÏö©Îêú Í∞úÏÑ†ÏÇ¨Ìï≠: {improvement.get('description', '')}")
        
        try:
            query_result = bq_client.execute_query(improved_sql)
            processing_time = (datetime.now() - start_time).total_seconds()
            
            if query_result["success"]:
                print(f"‚úÖ Í∞úÏÑ†Îêú ÏøºÎ¶¨ Ïã§Ìñâ ÏÑ±Í≥µ! ({processing_time:.2f}Ï¥à)")
                print(f"üìä Í≤∞Í≥º: {query_result['returned_rows']}Í∞ú Ìñâ Î∞òÌôò")
                
                # ÏÑ±Í≥µ ÌÜµÍ≥Ñ ÏóÖÎç∞Ïù¥Ìä∏
                self.performance_stats["optimization_applied"] += 1
                
                return {
                    "execution_type": "execute_with_improvements",
                    "success": True,
                    "sql_query": improved_sql,
                    "original_sql": improvement.get('original_sql', ''),
                    "query_result": query_result,
                    "processing_time": processing_time,
                    "improvements_applied": True,
                    "improvement_details": {
                        "type": improvement.get('issue_type', ''),
                        "description": improvement.get('description', ''),
                        "confidence": improvement.get('confidence', 0),
                        "changes_made": improvement.get('changes_made', [])
                    }
                }
            else:
                print(f"‚ùå Í∞úÏÑ†Îêú ÏøºÎ¶¨ÎèÑ Ïã§Ìñâ Ïã§Ìå®: {query_result.get('error', '')}")
                return {
                    "execution_type": "execute_with_improvements",
                    "success": False,
                    "sql_query": improved_sql,
                    "error": query_result.get('error', ''),
                    "processing_time": processing_time,
                    "improvements_applied": True,
                    "improvement_failed": True
                }
                
        except Exception as e:
            processing_time = (datetime.now() - start_time).total_seconds()
            logger.error(f"Improved SQL execution failed: {str(e)}")
            return {
                "execution_type": "execute_with_improvements",
                "success": False,
                "sql_query": improved_sql,
                "error": str(e),
                "processing_time": processing_time
            }
    
    def _update_generation_stats(self, processing_time: float):
        """ÏÉùÏÑ± ÌÜµÍ≥Ñ ÏóÖÎç∞Ïù¥Ìä∏"""
        total_queries = self.performance_stats["simple_queries"] + self.performance_stats["complex_queries"]
        if total_queries > 0:
            current_avg = self.performance_stats["avg_generation_time"]
            new_avg = ((current_avg * (total_queries - 1)) + processing_time) / total_queries
            self.performance_stats["avg_generation_time"] = new_avg
    
    def _add_to_generation_history(self, query: str, result: Dict):
        """ÏÉùÏÑ± ÌûàÏä§ÌÜ†Î¶¨Ïóê Ï∂îÍ∞Ä"""
        self.generation_history.append({
            "timestamp": datetime.now().isoformat(),
            "query": query,
            "generation_type": result.get("generation_type"),
            "complexity": result.get("complexity"),
            "processing_time": result.get("processing_time", 0),
            "optimization_applied": result.get("optimization_applied", False)
        })
        
        # ÌûàÏä§ÌÜ†Î¶¨ ÌÅ¨Í∏∞ Ï†úÌïú
        if len(self.generation_history) > 50:
            self.generation_history = self.generation_history[-50:]
    
    def _create_fallback_result(self, generation_type: str, error_msg: str) -> Dict[str, Any]:
        """ÏÉùÏÑ± Ïã§Ìå®Ïãú ÎåÄÏ≤¥ Í≤∞Í≥º ÏÉùÏÑ±"""
        return {
            "generation_type": generation_type,
            "sql_query": "-- SQL ÏÉùÏÑ± Ïã§Ìå®Î°ú Ïù∏Ìïú Í∏∞Î≥∏ ÏøºÎ¶¨\nSELECT 'ERROR' as message;",
            "error": error_msg,
            "fallback": True,
            "confidence": 0.0
        }
    
    def get_agent_statistics(self) -> Dict[str, Any]:
        """Agent ÌÜµÍ≥Ñ Ï†ïÎ≥¥ Î∞òÌôò"""
        total_queries = self.performance_stats["simple_queries"] + self.performance_stats["complex_queries"]
        
        if total_queries == 0:
            return {"message": "ÏÉùÏÑ± Ïù¥Î†•Ïù¥ ÏóÜÏäµÎãàÎã§."}
        
        optimization_rate = (self.performance_stats["optimization_applied"] / total_queries) * 100
        
        return {
            "total_generated": total_queries,
            "simple_queries": self.performance_stats["simple_queries"],
            "complex_queries": self.performance_stats["complex_queries"],
            "optimization_rate": round(optimization_rate, 2),
            "avg_generation_time": round(self.performance_stats["avg_generation_time"], 3),
            "performance_grade": "A" if optimization_rate > 70 and self.performance_stats["avg_generation_time"] < 2.0 else "B"
        }

# Agent ÏÉùÏÑ± Ìó¨Ìçº Ìï®Ïàò
def create_query_architect_agent(custom_config: Optional[Dict[str, Any]] = None) -> QueryArchitectAgent:
    """QueryArchitect Agent ÏÉùÏÑ±"""
    config = create_agent_config(
        name="query_architect",
        specialization="sql_design_optimization",
        model="gpt-4",
        temperature=0.1,
        max_tokens=1500,
        **(custom_config or {})
    )
    
    return QueryArchitectAgent(config)