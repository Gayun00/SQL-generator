from typing import Literal, TypedDict
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver
from multiAgents.config import AGENTS, LLM_MODEL, DEBUG, HUMAN_IN_THE_LOOP
from multiAgents.human_review import simple_human_review, human_review_node

# LLM ì •ì˜
llm = ChatOpenAI(model=LLM_MODEL)

# ì‚¬ìš© ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸ ëª©ë¡
members = list(AGENTS.keys())
options = members + ["FINISH"]

# ì—ì´ì „íŠ¸ ì„¤ëª… ìƒì„±
agent_descriptions = "\n".join([
    f"- {name}: {info['description']}"
    for name, info in AGENTS.items()
])

# Supervisor ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
system_prompt = (
    "You are a supervisor tasked with managing a conversation between the "
    f"following workers: {', '.join(members)}.\n\n"
    "Worker Capabilities:\n"
    f"{agent_descriptions}\n\n"
    "Instructions:\n"
    "1. Analyze the user's request and conversation history\n"
    "2. Determine which worker should handle the next step\n"
    "3. Consider the natural flow of tasks (e.g., get schema before generating SQL)\n"
    "4. When the user's request has been fully addressed, respond with FINISH\n\n"
    "Make your decision based on what needs to be done next, not on explicit rules."
)

class Router(TypedDict):
    """Worker to route to next. If no workers needed, route to FINISH."""
    next: Literal["UserCommunicator", "SchemaAnalyzer", "SQLGenerator", "FINISH"]

def router_node(state) -> dict:
    """
    Router node that determines which worker should handle the next step.
    
    Args:
        state: Current conversation state with messages
        
    Returns:
        dict: Contains the next worker to execute or FINISH
    """
    if DEBUG:
        print("\n" + "="*50)
        print("SUPERVISOR ROUTER ANALYSIS")
        print("="*50)
    
    # ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ êµ¬ì„±
    messages = [{"role": "system", "content": system_prompt}]
    
    # ìƒíƒœì—ì„œ ë©”ì‹œì§€ ì¶”ì¶œ ë° í¬ë§·íŒ…
    for msg in state["messages"]:
        if hasattr(msg, '__class__'):
            msg_type = msg.__class__.__name__
            if msg_type == "HumanMessage":
                messages.append({"role": "user", "content": msg.content})
            elif msg_type == "AIMessage":
                messages.append({"role": "assistant", "content": msg.content if msg.content else "Tool executed"})
            elif msg_type == "ToolMessage":
                messages.append({"role": "assistant", "content": f"Tool result: {msg.content}"})
    
    # LLMì„ í†µí•´ ë‹¤ìŒ ì‘ì—…ì ê²°ì •
    response = llm.with_structured_output(Router).invoke(messages)
    next_worker = response["next"]
    
    if DEBUG:
        print(f"ğŸ¤– Router decision: Route to {next_worker}")
        if next_worker != "FINISH":
            print(f"Reason: {AGENTS.get(next_worker, {}).get('description', 'Unknown')}")
    
    return {"next": next_worker}


# Supervisor ë‚´ë¶€ ê·¸ë˜í”„ ìƒì„±
def create_supervisor_graph():
    """
    Supervisor ë‚´ë¶€ ê·¸ë˜í”„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Returns:
        StateGraph: ì»´íŒŒì¼ëœ supervisor ê·¸ë˜í”„
    """
    from multiAgents.state import AgentState
    from multiAgents.agents.user_communicator_agent import user_node
    from multiAgents.agents.schema_analyzer_agent import schema_node
    from multiAgents.agents.sql_generator_agent import sql_node
    
    # ê·¸ë˜í”„ ìƒì„±
    workflow = StateGraph(AgentState)
    
    # Router ë…¸ë“œ ì¶”ê°€ (ë‹¤ìŒ ì—ì´ì „íŠ¸ ê²°ì •)
    workflow.add_node("Router", router_node)
    
    # ì—ì´ì „íŠ¸ ë…¸ë“œë“¤ ì¶”ê°€
    workflow.add_node("UserCommunicator", user_node)
    workflow.add_node("SchemaAnalyzer", schema_node)
    workflow.add_node("SQLGenerator", sql_node)
    
    # Human-in-the-Loopê°€ í™œì„±í™”ëœ ê²½ìš° HumanReview ë…¸ë“œ ì¶”ê°€
    if HUMAN_IN_THE_LOOP:
        workflow.add_node("HumanReview", human_review_node)
    
    # ì‹œì‘ì  ì„¤ì •
    workflow.set_entry_point("Router")
    
    # Routerì—ì„œ ë‹¤ìŒ ë…¸ë“œë¡œì˜ conditional edges
    if HUMAN_IN_THE_LOOP:
        # Human Reviewë¥¼ ê±°ì³ì„œ ì—ì´ì „íŠ¸ë¡œ ê°€ëŠ” êµ¬ì¡°
        def router_decision(x):
            next_step = x.get("next", "FINISH")
            if DEBUG:
                print(f"ğŸ”€ Router decision function called with: {x}")
                print(f"ğŸ”€ Next step extracted: {next_step}")
            
            if next_step in ["UserCommunicator", "SchemaAnalyzer", "SQLGenerator"]:
                if DEBUG:
                    print(f"ğŸ”€ Routing to HumanReview for: {next_step}")
                return "HumanReview"
            else:
                if DEBUG:
                    print(f"ğŸ”€ Routing to FINISH")
                return "FINISH"
        
        workflow.add_conditional_edges(
            "Router",
            router_decision,
            {"HumanReview": "HumanReview", "FINISH": END}
        )
        
        # HumanReviewì—ì„œ ì—ì´ì „íŠ¸ë¡œ
        workflow.add_conditional_edges(
            "HumanReview",
            lambda x: x["next"],
            {
                "UserCommunicator": "UserCommunicator",
                "SchemaAnalyzer": "SchemaAnalyzer", 
                "SQLGenerator": "SQLGenerator",
                "FINISH": END
            }
        )
    else:
        # ì§ì ‘ ì—ì´ì „íŠ¸ë¡œ ê°€ëŠ” êµ¬ì¡°
        workflow.add_conditional_edges(
            "Router",
            lambda x: x["next"],
            {
                "UserCommunicator": "UserCommunicator",
                "SchemaAnalyzer": "SchemaAnalyzer",
                "SQLGenerator": "SQLGenerator",
                "FINISH": END
            }
        )
    
    # ê° ì—ì´ì „íŠ¸ì—ì„œ Routerë¡œ ëŒì•„ê°€ëŠ” edge
    workflow.add_edge("UserCommunicator", "Router")
    workflow.add_edge("SchemaAnalyzer", "Router")
    workflow.add_edge("SQLGenerator", "Router")
    
    # ê·¸ë˜í”„ ì»´íŒŒì¼
    if HUMAN_IN_THE_LOOP:
        memory = MemorySaver()
        return workflow.compile(checkpointer=memory, interrupt_before=["HumanReview"])
    else:
        return workflow.compile()


# Supervisor ê·¸ë˜í”„ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
supervisor_graph = create_supervisor_graph()


def supervisor_node(state) -> dict:
    """
    Supervisor node that manages the internal graph workflow.
    
    Args:
        state: Current conversation state with messages
        
    Returns:
        dict: Updated state after running the supervisor graph
    """
    if DEBUG:
        print("\n" + "="*50)
        print("SUPERVISOR STARTING INTERNAL GRAPH")
        print("="*50)
    
    try:
        if HUMAN_IN_THE_LOOP:
            from langgraph.errors import GraphInterrupt
            from multiAgents.human_review import simple_human_review
            
            # Human-in-the-loopê°€ í™œì„±í™”ëœ ê²½ìš° ì¤‘ë‹¨ ì²˜ë¦¬
            config = {"configurable": {"thread_id": "default"}}
            
            try:
                # ì²« ë²ˆì§¸ ì‹¤í–‰ (ì¤‘ë‹¨ë  ìˆ˜ ìˆìŒ)
                result = supervisor_graph.invoke(state, config)
                if DEBUG:
                    print("="*50)
                    print("SUPERVISOR INTERNAL GRAPH COMPLETED")
                    print("="*50)
                return {**result, "next": "FINISH"}
                
            except GraphInterrupt:
                # ì¤‘ë‹¨ëœ ê²½ìš° í˜„ì¬ ìƒíƒœ í™•ì¸
                current_state = supervisor_graph.get_state(config)
                next_worker = current_state.values.get("next", "FINISH")
                
                if DEBUG:
                    print(f"ğŸš¦ Graph interrupted. Next worker: {next_worker}")
                
                # Human review ìˆ˜í–‰
                if next_worker != "FINISH":
                    if simple_human_review(f"Route to {next_worker}"):
                        # ìŠ¹ì¸ëœ ê²½ìš° ê³„ì† ì§„í–‰
                        result = supervisor_graph.invoke(None, config)
                        if DEBUG:
                            print("="*50)
                            print("SUPERVISOR INTERNAL GRAPH COMPLETED")
                            print("="*50)
                        return {**result, "next": "FINISH"}
                    else:
                        # ê±°ë¶€ëœ ê²½ìš° ì¢…ë£Œ
                        return {**state, "next": "FINISH"}
                else:
                    return {**state, "next": "FINISH"}
        else:
            # Human-in-the-loopê°€ ë¹„í™œì„±í™”ëœ ê²½ìš° ì¼ë°˜ ì‹¤í–‰
            result = supervisor_graph.invoke(state)
            
            if DEBUG:
                print("="*50)
                print("SUPERVISOR INTERNAL GRAPH COMPLETED")
                print("="*50)
            
            return {**result, "next": "FINISH"}
        
    except Exception as e:
        if DEBUG:
            print(f"âŒ Supervisor Graph Error: {type(e).__name__}: {str(e)}")
            import traceback
            traceback.print_exc()
        
        # ì—ëŸ¬ ë°œìƒ ì‹œ FINISHë¡œ ì„¤ì •
        return {**state, "next": "FINISH"}
