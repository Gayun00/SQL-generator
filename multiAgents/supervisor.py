from typing import Literal, TypedDict
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage
from multiAgents.config import AGENTS, LLM_MODEL, DEBUG, HUMAN_IN_THE_LOOP
from multiAgents.human_review import simple_human_review

# LLM ì •ì˜
llm = ChatOpenAI(model=LLM_MODEL)

# ì‚¬ìš© ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸ ëª©ë¡
members = list(AGENTS.keys())
options = members + ["FINISH"]

# ì—ì´ì „íŠ¸ ì„¤ëª… ìƒì„±
agent_descriptions = "\n".join([
    f"- {name}: {info['description']}"
    for name, info in AGENTS.items()
])

# Supervisor ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
system_prompt = (
    "You are a supervisor tasked with managing a conversation between the "
    f"following workers: {', '.join(members)}.\n\n"
    "Worker Capabilities:\n"
    f"{agent_descriptions}\n\n"
    "Instructions:\n"
    "1. Analyze the user's request and conversation history\n"
    "2. Determine which worker should handle the next step\n"
    "3. Consider the natural flow of tasks (e.g., get schema before generating SQL)\n"
    "4. When the user's request has been fully addressed, respond with FINISH\n\n"
    "Make your decision based on what needs to be done next, not on explicit rules."
)

class Router(TypedDict):
    """Worker to route to next. If no workers needed, route to FINISH."""
    next: Literal["UserCommunicator", "SchemaAnalyzer", "SQLGenerator", "FINISH"]

def supervisor_node(state) -> dict:
    """
    Supervisor node that manages the workflow between workers.
    
    Args:
        state: Current conversation state with messages
        
    Returns:
        dict: Contains the next worker to execute or FINISH
    """
    if DEBUG:
        print("\n" + "="*50)
        print("SUPERVISOR ANALYSIS")
        print("="*50)
    
    # ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ êµ¬ì„±
    messages = [{"role": "system", "content": system_prompt}]
    
    # ìƒíƒœì—ì„œ ë©”ì‹œì§€ ì¶”ì¶œ ë° í¬ë§·íŒ…
    for msg in state["messages"]:
        if hasattr(msg, '__class__'):
            msg_type = msg.__class__.__name__
            if msg_type == "HumanMessage":
                messages.append({"role": "user", "content": msg.content})
            elif msg_type == "AIMessage":
                messages.append({"role": "assistant", "content": msg.content if msg.content else "Tool executed"})
            elif msg_type == "ToolMessage":
                messages.append({"role": "assistant", "content": f"Tool result: {msg.content}"})
    
    # LLMì„ í†µí•´ ë‹¤ìŒ ì‘ì—…ì ê²°ì •
    response = llm.with_structured_output(Router).invoke(messages)
    next_worker = response["next"]
    
    if DEBUG:
        print(f"ğŸ¤– Supervisor decision: Route to {next_worker}")
        if next_worker != "FINISH":
            print(f"Reason: {AGENTS.get(next_worker, {}).get('description', 'Unknown')}")
    
    # FINISHì¸ ê²½ìš° ë°”ë¡œ ë°˜í™˜
    if next_worker == "FINISH":
        return {"next": next_worker}
    
    # Human-in-the-Loopê°€ í™œì„±í™”ëœ ê²½ìš° human review ì‹¤í–‰
    if HUMAN_IN_THE_LOOP:
        if not simple_human_review(f"Execute {next_worker}"):
            return {"next": "FINISH"}
    
    # ì—ì´ì „íŠ¸ ì‹¤í–‰
    result_state = execute_agent(next_worker, state)
    
    # ì—ì´ì „íŠ¸ ì‹¤í–‰ í›„ ë‹¤ìŒ ë‹¨ê³„ ê²°ì •ì´ í•„ìš”í•œì§€ í™•ì¸
    # ë§Œì•½ ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆê±°ë‚˜ ë” ì´ìƒ ì§„í–‰í•  ê²ƒì´ ì—†ë‹¤ë©´ FINISH
    if should_continue_workflow(result_state):
        # ë‹¤ìŒ ë‹¨ê³„ë¥¼ ìœ„í•´ Supervisorë¡œ ëŒì•„ê°
        result_state["next"] = "Supervisor"
    else:
        # ì‘ì—… ì™„ë£Œ
        result_state["next"] = "FINISH"
    
    return result_state


def should_continue_workflow(state: dict) -> bool:
    """
    ì›Œí¬í”Œë¡œìš°ë¥¼ ê³„ì† ì§„í–‰í• ì§€ ê²°ì •í•©ë‹ˆë‹¤.
    
    Args:
        state: í˜„ì¬ ìƒíƒœ
        
    Returns:
        bool: Trueë©´ ê³„ì† ì§„í–‰, Falseë©´ ì™„ë£Œ
    """
    # ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±: ë©”ì‹œì§€ê°€ ìˆê³  ì—ëŸ¬ê°€ ì—†ìœ¼ë©´ ê³„ì† ì§„í–‰
    messages = state.get("messages", [])
    if not messages:
        return False
    
    # ë§ˆì§€ë§‰ ë©”ì‹œì§€ê°€ ì™„ë£Œë¥¼ ë‚˜íƒ€ë‚´ëŠ” ê²½ìš° ì¢…ë£Œ
    last_message = messages[-1] if messages else None
    if last_message and hasattr(last_message, 'content'):
        content = last_message.content.lower()
        if any(keyword in content for keyword in ["complete", "finished", "done", "success"]):
            return False
    
    # ê¸°ë³¸ì ìœ¼ë¡œëŠ” ê³„ì† ì§„í–‰ (ë‚˜ì¤‘ì— ë” ì •êµí•œ ë¡œì§ ì¶”ê°€ ê°€ëŠ¥)
    return True


def execute_agent(agent_name: str, state: dict) -> dict:
    """
    ì§€ì •ëœ ì—ì´ì „íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
    
    Args:
        agent_name: ì‹¤í–‰í•  ì—ì´ì „íŠ¸ ì´ë¦„
        state: í˜„ì¬ ìƒíƒœ
        
    Returns:
        dict: ì—ì´ì „íŠ¸ ì‹¤í–‰ ê²°ê³¼ê°€ í¬í•¨ëœ ìƒíƒœ
    """
    if DEBUG:
        print(f"\nğŸš€ Executing agent: {agent_name}")
    
    # ê° ì—ì´ì „íŠ¸ë³„ ì‹¤í–‰ ë¡œì§
    if agent_name == "UserCommunicator":
        from multiAgents.agents.user_communicator_agent import user_node
        return user_node(state)
    elif agent_name == "SchemaAnalyzer":
        from multiAgents.agents.schema_analyzer_agent import schema_node
        return schema_node(state)
    elif agent_name == "SQLGenerator":
        from multiAgents.agents.sql_generator_agent import sql_node
        return sql_node(state)
    else:
        if DEBUG:
            print(f"âŒ Unknown agent: {agent_name}")
        return state
