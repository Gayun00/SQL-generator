import os
from dotenv import load_dotenv
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver
from langchain_core.messages import HumanMessage

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# LangSmith ì¶”ì ì„ ìœ„í•œ í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (ì„ íƒ ì‚¬í•­)
# os.environ["LANGCHAIN_TRACING_V2"] = "true"
# os.environ["LANGCHAIN_API_KEY"] = "YOUR_LANGCHAIN_API_KEY"

from multiAgents.state import AgentState
from multiAgents.supervisor import supervisor_node
from multiAgents.agents.schema_analyzer_agent import schema_node
from multiAgents.agents.sql_generator_agent import sql_node
from multiAgents.human_review import human_review_node
from multiAgents.config import AGENTS, DEFAULT_RECURSION_LIMIT, DEBUG, HUMAN_IN_THE_LOOP

# --- ê·¸ë˜í”„ ìƒì„± ---
workflow = StateGraph(AgentState)

# ë…¸ë“œ ì¶”ê°€
workflow.add_node("Supervisor", supervisor_node)
workflow.add_node("SchemaAnalyzer", schema_node)
workflow.add_node("SQLGenerator", sql_node)

# Human-in-the-Loopê°€ í™œì„±í™”ëœ ê²½ìš° HumanReview ë…¸ë“œ ì¶”ê°€
if HUMAN_IN_THE_LOOP:
    workflow.add_node("HumanReview", human_review_node)

# ì—£ì§€(ì—°ê²°) ì •ì˜
if HUMAN_IN_THE_LOOP:
    # Human-in-the-Loop ëª¨ë“œ: Supervisor â†’ HumanReview â†’ Agent/FINISH
    workflow.add_conditional_edges(
        "Supervisor",
        lambda x: "HumanReview" if x["next"] != "FINISH" else "FINISH",
        {"HumanReview": "HumanReview", "FINISH": END}
    )
    
    # HumanReviewì—ì„œ Agent ë˜ëŠ” Supervisor ë˜ëŠ” FINISHë¡œ
    review_edge_mapping = {agent: agent for agent in AGENTS.keys()}
    review_edge_mapping["Supervisor"] = "Supervisor"
    review_edge_mapping["FINISH"] = END
    
    workflow.add_conditional_edges(
        "HumanReview",
        lambda x: x["next"],
        review_edge_mapping
    )
    
    # ê° ì—ì´ì „íŠ¸ì—ì„œ ë‹¤ì‹œ Supervisorë¡œ
    for agent_name in AGENTS.keys():
        workflow.add_edge(agent_name, "Supervisor")
        
else:
    # ê¸°ë³¸ ëª¨ë“œ: Supervisor â†’ Agent ì§ì ‘ ì—°ê²°
    edge_mapping = {agent: agent for agent in AGENTS.keys()}
    edge_mapping["FINISH"] = END
    
    workflow.add_conditional_edges(
        "Supervisor",
        lambda x: x["next"],
        edge_mapping
    )
    
    # ê° ì—ì´ì „íŠ¸ì—ì„œ ë‹¤ì‹œ Supervisorë¡œ
    for agent_name in AGENTS.keys():
        workflow.add_edge(agent_name, "Supervisor")

# ì‹œì‘ì  ì„¤ì •
workflow.set_entry_point("Supervisor")

# ê·¸ë˜í”„ ì»´íŒŒì¼ (Human-in-the-Loopê°€ í™œì„±í™”ëœ ê²½ìš° interrupt_before ì„¤ì •)
if HUMAN_IN_THE_LOOP:
    memory = MemorySaver()
    graph = workflow.compile(checkpointer=memory, interrupt_before=["HumanReview"])
else:
    graph = workflow.compile()

def run_supervisor(query: str):
    """Supervisorë¥¼ ì‹¤í–‰í•˜ì—¬ ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì„ ë™ì‘ì‹œí‚µë‹ˆë‹¤."""
    print(f"ğŸ” Query: {query}\n")
    config = {
        "configurable": {"thread_id": "main_thread"},
        "recursion_limit": DEFAULT_RECURSION_LIMIT
    }

    # ì´ˆê¸° ì§ˆë¬¸ìœ¼ë¡œ ê·¸ë˜í”„ ì‹¤í–‰ ì‹œì‘
    if HUMAN_IN_THE_LOOP:
        # Human-in-the-Loop ëª¨ë“œì—ì„œëŠ” interruptë¥¼ ì²˜ë¦¬
        state = {"messages": [HumanMessage(content=query)]}
        
        while True:
            # ë‹¤ìŒ interruptê¹Œì§€ ì‹¤í–‰
            result = graph.invoke(state, config)
            
            # interruptê°€ ë°œìƒí–ˆëŠ”ì§€ í™•ì¸
            graph_state = graph.get_state(config)
            if graph_state.next:
                # interruptê°€ ë°œìƒí•œ ê²½ìš°, HumanReview ë…¸ë“œê°€ ì‹¤í–‰ë  ì˜ˆì •
                # í˜„ì¬ ìƒíƒœë¥¼ ê°€ì ¸ì™€ì„œ human_review_node ì‹¤í–‰
                current_state = graph_state.values
                human_result = human_review_node(current_state)
                
                # FINISHê°€ ì„ íƒëœ ê²½ìš° ì¢…ë£Œ
                if human_result["next"] == "FINISH":
                    print("\nğŸ¯ Task completed by user choice!")
                    break
                
                # human_resultë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê·¸ë˜í”„ ìƒíƒœ ì—…ë°ì´íŠ¸
                update_data = {"next": human_result["next"]}
                if "messages" in human_result:
                    update_data["messages"] = human_result["messages"]
                
                # ê·¸ë˜í”„ ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸
                graph.update_state(config, update_data)
                
                # ì—…ë°ì´íŠ¸ëœ ìƒíƒœë¡œ ë‹¤ìŒ iteration ì¤€ë¹„
                state = None  # invoke(None, config)ëŠ” í˜„ì¬ ìƒíƒœì—ì„œ ê³„ì† ì‹¤í–‰
                
            else:
                # interruptê°€ ì—†ëŠ” ê²½ìš° (ì‘ì—… ì™„ë£Œ)
                print("\nğŸ¯ Task completed successfully!")
                break
    else:
        # ê¸°ë³¸ ëª¨ë“œ: ê¸°ì¡´ ë°©ì‹
        events = graph.stream({"messages": [HumanMessage(content=query)]}, config)
        
        for chunk in events:
            for node, output in chunk.items():
                print(f"\nğŸ¤– Node '{node}' output:")
                print("-" * 30)
                if "messages" in output:
                    for msg in output["messages"]:
                        print(f"Type: {type(msg).__name__}")
                        print(f"Content: {msg.content}")
                        print()
                else:
                    print(output)


if __name__ == "__main__":
    # OPENAI_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
    if not os.getenv("OPENAI_API_KEY"):
        raise ValueError("OPENAI_API_KEYê°€ í™˜ê²½ ë³€ìˆ˜ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    # ê·¸ë˜í”„ ë‹¤ì´ì–´ê·¸ë¨ ì¶œë ¥
    from multiAgents.utils import print_graph
    print_graph(graph)

    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    print("\n" + "="*50)
    print("Multi-Agent SQL Generator")
    print("="*50)
    
    run_supervisor("users í…Œì´ë¸”ì˜ ëª¨ë“  ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” SQLì„ ë§Œë“¤ì–´ì¤˜. ë°ì´í„°ë² ì´ìŠ¤ ì´ë¦„ì€ 'my_db'ì•¼.")
