from google.cloud import bigquery
from google.oauth2 import service_account
from core.config import BIGQUERY_CONFIG
import json
import os
from typing import Dict, List, Optional

class BigQueryClient:
    def __init__(self):
        self.keyfile_path = BIGQUERY_CONFIG["keyfile_path"]
        self.default_dataset = BIGQUERY_CONFIG["default_dataset"]
        self.target_tables = [table.strip() for table in BIGQUERY_CONFIG["target_tables"] if table.strip()]
        self.project_id = None  # keyfileì—ì„œ ì¶”ì¶œ
        self.client = None
        self.schema_info = {}
        self.full_dataset_path = None  # project_id.dataset í˜•ì‹
        
    def connect(self) -> bool:
        """BigQuery í´ë¼ì´ì–¸íŠ¸ ì—°ê²°"""
        try:
            # keyfile.jsonì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
            if not os.path.exists(self.keyfile_path):
                print(f"âŒ keyfileì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.keyfile_path}")
                print("ğŸ’¡ keyfile.jsonì„ í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ì— ë°°ì¹˜í•˜ì„¸ìš”.")
                return False
            
            # keyfileì—ì„œ project_id ì¶”ì¶œ
            with open(self.keyfile_path, 'r') as f:
                keyfile_data = json.load(f)
                self.project_id = keyfile_data.get('project_id')
                
            if not self.project_id:
                print("âŒ keyfile.jsonì—ì„œ project_idë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                print("ğŸ’¡ ì˜¬ë°”ë¥¸ ì„œë¹„ìŠ¤ ê³„ì • í‚¤ íŒŒì¼ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.")
                return False
            
            # ì„œë¹„ìŠ¤ ê³„ì • í‚¤ íŒŒì¼ë¡œ ì¸ì¦
            credentials = service_account.Credentials.from_service_account_file(
                self.keyfile_path
            )
            
            self.client = bigquery.Client(
                project=self.project_id,
                credentials=credentials
            )
            
            # ì™„ì „í•œ ë°ì´í„°ì…‹ ê²½ë¡œ ì„¤ì •
            if self.default_dataset:
                self.full_dataset_path = f"{self.project_id}.{self.default_dataset}"
            
            # ì—°ê²° í…ŒìŠ¤íŠ¸
            test_query = "SELECT 1 as test_connection"
            self.client.query(test_query).result()
            print(f"âœ… BigQuery ì—°ê²° ì„±ê³µ: {self.project_id}")
            print(f"ğŸ“ ì‚¬ìš©ëœ keyfile: {self.keyfile_path}")
            if self.full_dataset_path:
                print(f"ğŸ“Š ê¸°ë³¸ ë°ì´í„°ì…‹ ê²½ë¡œ: {self.full_dataset_path}")
            return True
            
        except FileNotFoundError:
            print(f"âŒ keyfileì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.keyfile_path}")
            print("ğŸ’¡ Google Cloud Consoleì—ì„œ ì„œë¹„ìŠ¤ ê³„ì • í‚¤ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ì—¬ keyfile.jsonìœ¼ë¡œ ì €ì¥í•˜ì„¸ìš”.")
            return False
        except json.JSONDecodeError:
            print(f"âŒ keyfile í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤: {self.keyfile_path}")
            print("ğŸ’¡ ì˜¬ë°”ë¥¸ JSON í˜•ì‹ì˜ ì„œë¹„ìŠ¤ ê³„ì • í‚¤ íŒŒì¼ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.")
            return False
        except Exception as e:
            print(f"âŒ BigQuery ì—°ê²° ì‹¤íŒ¨: {str(e)}")
            print("ğŸ’¡ í™•ì¸ì‚¬í•­:")
            print("  1. keyfile.jsonì˜ ì„œë¹„ìŠ¤ ê³„ì •ì— BigQuery ê¶Œí•œì´ ìˆëŠ”ì§€ í™•ì¸")
            print("  2. BigQuery APIê°€ í™œì„±í™”ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸")
            return False
    
    def get_dataset_tables(self, dataset_id: str) -> List[str]:
        """ë°ì´í„°ì…‹ì˜ ëª¨ë“  í…Œì´ë¸” ëª©ë¡ ì¡°íšŒ"""
        try:
            dataset_ref = self.client.dataset(dataset_id)
            tables = list(self.client.list_tables(dataset_ref))
            table_list = [table.table_id for table in tables]
            print(f"     ğŸ“Š ë°œê²¬ëœ í…Œì´ë¸”: {table_list}")
            return table_list
        except Exception as e:
            error_msg = str(e)
            print(f"     âŒ í…Œì´ë¸” ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨ ({dataset_id}): {error_msg}")
            
            # êµ¬ì²´ì ì¸ ì—ëŸ¬ ìœ í˜•ë³„ ì•ˆë‚´
            if "404" in error_msg or "Not found" in error_msg:
                print(f"     ğŸ’¡ ë°ì´í„°ì…‹ '{dataset_id}'ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                print(f"     ğŸ’¡ Google Cloud Consoleì—ì„œ ë°ì´í„°ì…‹ ì´ë¦„ì„ í™•ì¸í•˜ì„¸ìš”.")
            elif "403" in error_msg or "Access Denied" in error_msg:
                print(f"     ğŸ’¡ ì„œë¹„ìŠ¤ ê³„ì •ì— ë°ì´í„°ì…‹ '{dataset_id}' ì ‘ê·¼ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤.")
                print(f"     ğŸ’¡ BigQuery Data Viewer ë˜ëŠ” BigQuery User ì—­í• ì„ ë¶€ì—¬í•˜ì„¸ìš”.")
            else:
                print(f"     ğŸ’¡ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ì…ë‹ˆë‹¤. ë„¤íŠ¸ì›Œí¬ë‚˜ API ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            
            return []
    
    def get_table_schema(self, dataset_id: str, table_id: str) -> Dict:
        """íŠ¹ì • í…Œì´ë¸”ì˜ ìŠ¤í‚¤ë§ˆ ì •ë³´ ì¡°íšŒ"""
        try:
            table_ref = self.client.dataset(dataset_id).table(table_id)
            table = self.client.get_table(table_ref)
            
            schema_info = {
                "table_name": f"{dataset_id}.{table_id}",
                "description": table.description or "",
                "columns": []
            }
            
            for field in table.schema:
                column_info = {
                    "name": field.name,
                    "type": field.field_type,
                    "mode": field.mode,
                    "description": field.description or ""
                }
                schema_info["columns"].append(column_info)
            
            return schema_info
            
        except Exception as e:
            error_msg = str(e)
            print(f"     âŒ í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ ì¡°íšŒ ì‹¤íŒ¨ ({dataset_id}.{table_id}): {error_msg}")
            
            # êµ¬ì²´ì ì¸ ì—ëŸ¬ ìœ í˜•ë³„ ì•ˆë‚´
            if "404" in error_msg or "Not found" in error_msg:
                print(f"     ğŸ’¡ í…Œì´ë¸” '{dataset_id}.{table_id}'ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                print(f"     ğŸ’¡ Google Cloud Consoleì—ì„œ í…Œì´ë¸” ì´ë¦„ì„ í™•ì¸í•˜ì„¸ìš”.")
            elif "403" in error_msg or "Access Denied" in error_msg:
                print(f"     ğŸ’¡ ì„œë¹„ìŠ¤ ê³„ì •ì— í…Œì´ë¸” '{dataset_id}.{table_id}' ì ‘ê·¼ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤.")
                print(f"     ğŸ’¡ BigQuery Data Viewer ì—­í• ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            else:
                print(f"     ğŸ’¡ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ì…ë‹ˆë‹¤. ë„¤íŠ¸ì›Œí¬ë‚˜ API ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”.")
                
            return {}
    
    def initialize_schema(self) -> Dict:
        """ìŠ¤í‚¤ë§ˆ ì •ë³´ ì´ˆê¸°í™”"""
        print("ğŸ” BigQuery ìŠ¤í‚¤ë§ˆ ì •ë³´ ìˆ˜ì§‘ ì¤‘...")
        
        if not self.client:
            print("âŒ BigQuery í´ë¼ì´ì–¸íŠ¸ê°€ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return {}
        
        try:
            # íƒ€ê²Ÿ í…Œì´ë¸”ì´ ì§€ì •ëœ ê²½ìš°
            if self.target_tables:
                print(f"ğŸ“‹ ì§€ì •ëœ í…Œì´ë¸”ë“¤ì„ ì¡°íšŒí•©ë‹ˆë‹¤: {self.target_tables}")
                for table_name in self.target_tables:
                    print(f"   ğŸ” ì²˜ë¦¬ ì¤‘: {table_name}")
                    if "." in table_name:
                        dataset_id, table_id = table_name.split(".", 1)
                    else:
                        dataset_id = self.default_dataset
                        table_id = table_name
                    
                    if not dataset_id:
                        print(f"   âš ï¸ ë°ì´í„°ì…‹ì´ ì§€ì •ë˜ì§€ ì•Šì€ í…Œì´ë¸”: {table_name}")
                        print(f"   ğŸ’¡ {table_name}ì„ dataset.table í˜•ì‹ìœ¼ë¡œ ì§€ì •í•˜ê±°ë‚˜ BIGQUERY_DEFAULT_DATASETì„ ì„¤ì •í•˜ì„¸ìš”.")
                        continue
                    
                    print(f"   ğŸ“Š ìŠ¤í‚¤ë§ˆ ì¡°íšŒ: {dataset_id}.{table_id}")
                    schema = self.get_table_schema(dataset_id, table_id)
                    if schema:
                        self.schema_info[f"{dataset_id}.{table_id}"] = schema
                        print(f"   âœ… ì„±ê³µ: {len(schema.get('columns', []))}ê°œ ì»¬ëŸ¼")
            
            # íƒ€ê²Ÿ í…Œì´ë¸”ì´ ì§€ì •ë˜ì§€ ì•Šì€ ê²½ìš° ê¸°ë³¸ ë°ì´í„°ì…‹ì˜ ëª¨ë“  í…Œì´ë¸” ì¡°íšŒ
            elif self.default_dataset:
                print(f"ğŸ“‹ ê¸°ë³¸ ë°ì´í„°ì…‹ì˜ ëª¨ë“  í…Œì´ë¸”ì„ ì¡°íšŒí•©ë‹ˆë‹¤: {self.default_dataset}")
                print(f"   ğŸ” ë°ì´í„°ì…‹ í…Œì´ë¸” ëª©ë¡ ì¡°íšŒ ì¤‘...")
                tables = self.get_dataset_tables(self.default_dataset)
                
                if not tables:
                    print(f"   âŒ ë°ì´í„°ì…‹ '{self.default_dataset}'ì—ì„œ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    print(f"   ğŸ’¡ í™•ì¸ì‚¬í•­:")
                    print(f"     1. ë°ì´í„°ì…‹ ì´ë¦„ì´ ì •í™•í•œì§€ í™•ì¸: {self.default_dataset}")
                    print(f"     2. ì„œë¹„ìŠ¤ ê³„ì •ì´ í•´ë‹¹ ë°ì´í„°ì…‹ì— ì ‘ê·¼ ê¶Œí•œì´ ìˆëŠ”ì§€ í™•ì¸")
                    print(f"     3. ë°ì´í„°ì…‹ì— í…Œì´ë¸”ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸")
                    return {}
                
                print(f"   ğŸ“Š ë°œê²¬ëœ í…Œì´ë¸” ìˆ˜: {len(tables)}")
                for table_id in tables:
                    print(f"   ğŸ” ìŠ¤í‚¤ë§ˆ ì¡°íšŒ: {self.default_dataset}.{table_id}")
                    schema = self.get_table_schema(self.default_dataset, table_id)
                    if schema:
                        self.schema_info[f"{self.default_dataset}.{table_id}"] = schema
                        print(f"   âœ… ì„±ê³µ: {len(schema.get('columns', []))}ê°œ ì»¬ëŸ¼")
            
            else:
                print("âŒ ì¡°íšŒí•  ë°ì´í„°ì…‹ ë˜ëŠ” í…Œì´ë¸”ì´ ì§€ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                print("ğŸ’¡ í•´ê²°ë°©ë²•:")
                print("   1. .env íŒŒì¼ì— BIGQUERY_DEFAULT_DATASET ì„¤ì •")
                print("   2. ë˜ëŠ” BIGQUERY_TARGET_TABLESì— dataset.table í˜•ì‹ìœ¼ë¡œ í…Œì´ë¸” ì§€ì •")
                return {}
            
            if not self.schema_info:
                print("âŒ ìŠ¤í‚¤ë§ˆ ì •ë³´ë¥¼ ìˆ˜ì§‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                print("ğŸ’¡ ê°€ëŠ¥í•œ ì›ì¸:")
                print("   1. ì§€ì •ëœ ë°ì´í„°ì…‹/í…Œì´ë¸”ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ")
                print("   2. ì„œë¹„ìŠ¤ ê³„ì •ì— BigQuery Data Viewer ê¶Œí•œì´ ì—†ìŒ")
                print("   3. ì˜ëª»ëœ ë°ì´í„°ì…‹/í…Œì´ë¸” ì´ë¦„")
                return {}
            
            print(f"âœ… ìŠ¤í‚¤ë§ˆ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ: {len(self.schema_info)}ê°œ í…Œì´ë¸”")
            return self.schema_info
            
        except Exception as e:
            print(f"âŒ ìŠ¤í‚¤ë§ˆ ì´ˆê¸°í™” ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}")
            print("ğŸ’¡ ìì„¸í•œ ì˜¤ë¥˜ ì •ë³´:")
            import traceback
            traceback.print_exc()
            return {}
    
    def get_schema_summary(self) -> str:
        """ìŠ¤í‚¤ë§ˆ ì •ë³´ë¥¼ ë¬¸ìì—´ë¡œ ìš”ì•½"""
        if not self.schema_info:
            return "ìŠ¤í‚¤ë§ˆ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        summary = []
        summary.append("=== BigQuery í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ ì •ë³´ ===\n")
        
        for table_name, schema in self.schema_info.items():
            summary.append(f"ğŸ“Š í…Œì´ë¸”: {table_name}")
            if schema.get("description"):
                summary.append(f"   ì„¤ëª…: {schema['description']}")
            
            summary.append("   ì»¬ëŸ¼:")
            for col in schema.get("columns", []):
                col_desc = f" - {col['description']}" if col.get("description") else ""
                summary.append(f"     â€¢ {col['name']} ({col['type']}, {col['mode']}){col_desc}")
            summary.append("")
        
        return "\n".join(summary)
    
    def execute_query(self, query: str, max_results: int = 100) -> Dict:
        """SQL ì¿¼ë¦¬ ì‹¤í–‰ ë° ê²°ê³¼ ë°˜í™˜"""
        if not self.client:
            return {
                "success": False,
                "error": "BigQuery í´ë¼ì´ì–¸íŠ¸ê°€ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
                "results": []
            }
        
        try:
            print(f"ğŸ” ì¿¼ë¦¬ ì‹¤í–‰ ì¤‘...")
            print(f"ğŸ“‹ Query: {query}")
            
            # ì¿¼ë¦¬ ì‹¤í–‰
            query_job = self.client.query(query)
            
            # ì¿¼ë¦¬ ì™„ë£Œ ëŒ€ê¸°
            query_result = query_job.result()
            
            # ê²°ê³¼ ê°€ì ¸ì˜¤ê¸° (ìµœëŒ€ ê²°ê³¼ ìˆ˜ ì œí•œ)
            results = []
            row_count = 0
            
            for row in query_result:
                if row_count >= max_results:
                    break
                    
                # Rowë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
                row_dict = {}
                for key, value in row.items():
                    # BigQuery íŠ¹ìˆ˜ íƒ€ì…ë“¤ì„ Python ê¸°ë³¸ íƒ€ì…ìœ¼ë¡œ ë³€í™˜
                    if hasattr(value, 'isoformat'):  # datetime ê°ì²´
                        row_dict[key] = value.isoformat()
                    elif hasattr(value, '__iter__') and not isinstance(value, (str, bytes)):  # ë¦¬ìŠ¤íŠ¸ë‚˜ ê¸°íƒ€ iterable
                        row_dict[key] = list(value)
                    else:
                        row_dict[key] = value
                        
                results.append(row_dict)
                row_count += 1
            
            # ì‹¤í–‰ í†µê³„ ì •ë³´ (QueryJobì—ì„œ ê°€ì ¸ì˜¤ê¸°)
            total_rows = len(results)  # ê¸°ë³¸ì ìœ¼ë¡œëŠ” ë°˜í™˜ëœ ê²°ê³¼ ìˆ˜ ì‚¬ìš©
            bytes_processed = 0
            
            try:
                # QueryJobì—ì„œ í†µê³„ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ë ¤ê³  ì‹œë„
                if hasattr(query_job, 'total_rows') and query_job.total_rows is not None:
                    total_rows = query_job.total_rows
                if hasattr(query_job, 'total_bytes_processed') and query_job.total_bytes_processed is not None:
                    bytes_processed = query_job.total_bytes_processed
            except AttributeError:
                # ì†ì„±ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
                pass
            
            print(f"âœ… ì¿¼ë¦¬ ì‹¤í–‰ ì™„ë£Œ!")
            print(f"   - ì²˜ë¦¬ëœ í–‰ ìˆ˜: {len(results)}")
            print(f"   - ì „ì²´ í–‰ ìˆ˜: {total_rows}")
            print(f"   - ì²˜ë¦¬ëœ ë°”ì´íŠ¸: {bytes_processed:,} bytes")
            
            if len(results) >= max_results and total_rows > max_results:
                print(f"âš ï¸ ê²°ê³¼ê°€ {max_results}ê°œë¡œ ì œí•œë˜ì—ˆìŠµë‹ˆë‹¤. (ì „ì²´: {total_rows}ê°œ)")
            
            return {
                "success": True,
                "results": results,
                "total_rows": total_rows,
                "returned_rows": len(results),
                "bytes_processed": bytes_processed,
                "query": query,
                "truncated": len(results) >= max_results and total_rows > max_results
            }
            
        except Exception as e:
            error_msg = str(e)
            print(f"âŒ ì¿¼ë¦¬ ì‹¤í–‰ ì‹¤íŒ¨: {error_msg}")
            
            # êµ¬ì²´ì ì¸ ì—ëŸ¬ ë¶„ì„
            error_type = "unknown"
            suggestion = "ì¿¼ë¦¬ ë¬¸ë²•ì„ í™•ì¸í•˜ì„¸ìš”."
            
            if "Syntax error" in error_msg or "Invalid" in error_msg:
                error_type = "syntax_error"
                suggestion = "SQL ë¬¸ë²•ì„ í™•ì¸í•˜ì„¸ìš”."
            elif "Table" in error_msg and "not found" in error_msg:
                error_type = "table_not_found"
                suggestion = "í…Œì´ë¸” ì´ë¦„ì„ í™•ì¸í•˜ì„¸ìš”. dataset.table í˜•ì‹ìœ¼ë¡œ ì‘ì„±í–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”."
            elif "Column" in error_msg and "not found" in error_msg:
                error_type = "column_not_found" 
                suggestion = "ì»¬ëŸ¼ ì´ë¦„ì„ í™•ì¸í•˜ì„¸ìš”."
            elif "Access Denied" in error_msg or "Permission" in error_msg:
                error_type = "permission_error"
                suggestion = "BigQuery ì ‘ê·¼ ê¶Œí•œì„ í™•ì¸í•˜ì„¸ìš”."
            elif "Query exceeded limit" in error_msg:
                error_type = "resource_limit"
                suggestion = "ì¿¼ë¦¬ê°€ ë„ˆë¬´ ë³µì¡í•©ë‹ˆë‹¤. LIMITì„ ì¶”ê°€í•˜ê±°ë‚˜ ì¡°ê±´ì„ ì¶”ê°€í•˜ì„¸ìš”."
            
            return {
                "success": False,
                "error": error_msg,
                "error_type": error_type,
                "suggestion": suggestion,
                "query": query,
                "results": []
            }
    
    def get_full_table_path(self, table_name: str) -> str:
        """í…Œì´ë¸”ëª…ì„ ì™„ì „í•œ BigQuery ê²½ë¡œë¡œ ë³€í™˜"""
        if not table_name:
            return ""
        
        # ì´ë¯¸ ë°±í‹±ìœ¼ë¡œ ê°ì‹¸ì ¸ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
        if table_name.startswith('`') and table_name.endswith('`'):
            return table_name
        
        # ì´ë¯¸ í”„ë¡œì íŠ¸.ë°ì´í„°ì…‹.í…Œì´ë¸” í˜•ì‹ì´ë©´ ë°±í‹±ë§Œ ì¶”ê°€
        if '.' in table_name and table_name.count('.') >= 2:
            return f"`{table_name}`"
        
        # í…Œì´ë¸”ëª…ë§Œ ìˆëŠ” ê²½ìš° ê¸°ë³¸ ë°ì´í„°ì…‹ ê²½ë¡œ ì¶”ê°€
        if self.full_dataset_path:
            if '.' in table_name:  # dataset.table í˜•ì‹
                return f"`{self.project_id}.{table_name}`"
            else:  # table í˜•ì‹
                return f"`{self.full_dataset_path}.{table_name}`"
        
        # ê¸°ë³¸ ë°ì´í„°ì…‹ì´ ì—†ìœ¼ë©´ ê²½ê³ ì™€ í•¨ê»˜ ì›ë³¸ ë°˜í™˜
        print(f"âš ï¸ ê¸°ë³¸ ë°ì´í„°ì…‹ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í…Œì´ë¸”ëª…: {table_name}")
        return table_name
    
    def get_information_schema_path(self, schema_type: str = "COLUMNS") -> str:
        """INFORMATION_SCHEMA ê²½ë¡œ ìƒì„±"""
        if self.full_dataset_path:
            return f"`{self.full_dataset_path}.INFORMATION_SCHEMA.{schema_type}`"
        return f"INFORMATION_SCHEMA.{schema_type}"

# ì „ì—­ í´ë¼ì´ì–¸íŠ¸ ì¸ìŠ¤í„´ìŠ¤
bq_client = BigQueryClient()